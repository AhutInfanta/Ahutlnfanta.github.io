<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>kafka概述（二）</title>
    <url>/rookie/2022/07/25/kafka/kafka2/</url>
    <content><![CDATA[<h2 id="1-kafka配置详解"><a href="#1-kafka配置详解" class="headerlink" title="1. kafka配置详解"></a>1. kafka配置详解</h2><h3 id="1-1-broker配置"><a href="#1-1-broker配置" class="headerlink" title="1.1 broker配置"></a>1.1 broker配置</h3><blockquote>
<ul>
<li><strong>broker.id</strong>：（必须配置）节点ID，必须全局唯一</li>
<li><strong>log.dir</strong>：（必须配置）日志存放目录，默认值（&#x2F;tmp&#x2F;kafka-logs），tmp目录会被系统定期清理</li>
<li><strong>zookeeper.connect</strong>：（必须配置）zookeeper连接</li>
<li><strong>auto.create.topics.enable</strong>：是否自动创建主题，默认为true</li>
<li><strong>auto.leader.rebalance.enable</strong>：分区leader自动负载均衡，默认true</li>
<li><strong>compression.type</strong>：压缩类型，可选值 (‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)</li>
</ul>
</blockquote>
<h3 id="1-2-producer配置"><a href="#1-2-producer配置" class="headerlink" title="1.2 producer配置"></a>1.2 producer配置</h3><blockquote>
<ul>
<li><strong>client.id</strong>：生产者客户端Id</li>
<li><strong>batch.size</strong>：批量发送数据大小，默认16K</li>
<li><strong>linger.ms</strong>：延迟时间，默认0</li>
<li><strong>buffer.memory</strong>：缓冲区大小，默认32M</li>
<li><strong>compression.type</strong>：消息压缩格式，默认none，可选none, gzip, snappy, lz4, or zstd</li>
<li><strong>acks</strong>：消息确认机制，默认all，即-1，可选[all, -1, 0, 1]，0-不需要回应，1-等leader落盘后回应，-1-所有副本落盘后回应</li>
<li><strong>partitioner.class</strong>：分区器类路径，默认DefaultPartitioner，还提供RoundRobinPartitioner，UniformStickyPartitioner</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
<li><strong>retries</strong>：重试次数，默认int最大值</li>
<li><strong>enable.idempotence</strong>：幂等性，默认true,根据&lt;pid,分区号，序列号&gt;去重</li>
<li><strong>max.in.flight.requests.per.connection</strong>：生产者在收到kafka响应前最大发送请求数，默认5</li>
<li><strong>transactional.id</strong>：事务ID，全局唯一，基于enable.idempotence</li>
</ul>
</blockquote>
<h3 id="1-3-consume配置"><a href="#1-3-consume配置" class="headerlink" title="1.3 consume配置"></a>1.3 consume配置</h3><blockquote>
<ul>
<li><strong>group.id</strong>：消费者所属的群组ID</li>
<li><strong>enable.auto.commit</strong>：自动提交，默认开启，一般关闭</li>
<li><strong>auto.offset.reset</strong>：有效值为“earliest”“latest”“none”,默认latest</li>
<li><strong>fetch.min.bytes</strong>：最小拉取字节数，默认1(B)，</li>
<li><strong>fetch.max.wait.mss</strong>：拉取最大等待时间数，默认500（ms），</li>
<li><strong>max-poll-records</strong>：一次请求最大拉取的消息条数，默认500</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
</ul>
</blockquote>
<h2 id="2-常用命令"><a href="#2-常用命令" class="headerlink" title="2. 常用命令"></a>2. 常用命令</h2><h3 id="2-1-启动停止"><a href="#2-1-启动停止" class="headerlink" title="2.1 启动停止"></a>2.1 启动停止</h3><blockquote>
<ul>
<li>.&#x2F;bin&#x2F;kafka-server-start.sh -daemon .&#x2F;config&#x2F;server.properties</li>
<li>.&#x2F;bin&#x2F;kafka-server-stop.sh</li>
</ul>
</blockquote>
<h3 id="2-2-主题（kafka-topic-sh）"><a href="#2-2-主题（kafka-topic-sh）" class="headerlink" title="2.2 主题（kafka-topic.sh）"></a>2.2 主题（kafka-topic.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
<li>–create</li>
<li>–delete</li>
<li>–describe</li>
<li>–partitions</li>
<li>–replication-factor</li>
<li>–list</li>
</ul>
</blockquote>
<h3 id="2-3-生产者（kafka-console-producer-sh）"><a href="#2-3-生产者（kafka-console-producer-sh）" class="headerlink" title="2.3 生产者（kafka-console-producer.sh）"></a>2.3 生产者（kafka-console-producer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
</ul>
</blockquote>
<h3 id="2-4-消费者（kafka-console-consumer-sh）"><a href="#2-4-消费者（kafka-console-consumer-sh）" class="headerlink" title="2.4 消费者（kafka-console-consumer.sh）"></a>2.4 消费者（kafka-console-consumer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称 –from-beginning</li>
<li>–group 指定消费组</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-分区原来是这样子</title>
    <url>/rookie/2022/07/30/kafka/kafka3/</url>
    <content><![CDATA[<h1 id="1-分区器"><a href="#1-分区器" class="headerlink" title="1. 分区器"></a>1. 分区器</h1><blockquote>
<p><em><strong>broker配置项：partitioner.class</strong></em></p>
<ul>
<li>org.apache.kafka.clients.producer.internals.DefaultPartitioner</li>
<li>org.apache.kafka.clients.producer.RoundRobinPartitioner</li>
<li>org.apache.kafka.clients.producer.Partitioner</li>
</ul>
</blockquote>
<h2 id="1-1-默认分区器（DefaultPartitioner）"><a href="#1-1-默认分区器（DefaultPartitioner）" class="headerlink" title="1.1 默认分区器（DefaultPartitioner）"></a>1.1 默认分区器（DefaultPartitioner）</h2><blockquote>
<ul>
<li>若发送时指定分区，则发送到指定的分区中</li>
<li>未指定分区，指定了Key，则Key的hashcode%分区数</li>
<li>均未指定，采取粘性规则，第一次随机选择分区，直到缓存满或者时间到发送完消息，下一次继续随机但不会选择上次使用的分区</li>
</ul>
</blockquote>
<h2 id="1-2-RoundRobinPartitioner"><a href="#1-2-RoundRobinPartitioner" class="headerlink" title="1.2 RoundRobinPartitioner"></a>1.2 RoundRobinPartitioner</h2><blockquote>
<p>这种分区策略是一系列连续记录中的每条记录将被发送到不同的分区（无论是否提供’key’），直到我们用完分区并重新开始。注意：有一个已知问题会在创建新批次时导致分布不均</p>
</blockquote>
<h2 id="1-3-UniformStickyPartitioner"><a href="#1-3-UniformStickyPartitioner" class="headerlink" title="1.3 UniformStickyPartitioner"></a>1.3 UniformStickyPartitioner</h2><blockquote>
<p>此分区策略将尝试坚持一个分区（无论是否提供了“key”），直到batch.size已满或已满linger.ms</p>
</blockquote>
<h2 id="1-4-自定义分区"><a href="#1-4-自定义分区" class="headerlink" title="1.4 自定义分区"></a>1.4 自定义分区</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义hash分区,实现Partitioner接口,重写partition方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartition</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes1, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取topic中partition数量</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="type">int</span> <span class="variable">partitionCount</span> <span class="operator">=</span> partitionInfoList.size();</span><br><span class="line">        <span class="comment">// 根据key的hash值计取模，计算出在哪个分区中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> Math.abs(String.valueOf(key).hashCode()) % partitionCount;</span><br><span class="line">        <span class="keyword">return</span> numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">kafkaProperties.put(<span class="string">&quot;partitioner.class&quot;</span>,<span class="string">&quot;com.pg.kafka.MyPartition&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="2-分区节点分布策略"><a href="#2-分区节点分布策略" class="headerlink" title="2. 分区节点分布策略"></a>2. 分区节点分布策略</h1><p>创建topic,分配时，规则是尽量均匀将所有分区副本分布在各个broker上</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --create --replication-factor 3  --partitions 16 --topic test2</span><br></pre></td></tr></table></figure>
<p>查看topic信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe  --topic test2</span><br></pre></td></tr></table></figure>
<img src="/rookie/2022/07/30/kafka/kafka3/topic-describe.png" class="" title="img.png">
<blockquote>
<p>分配规则大致如下，借鉴网上教程的图</p>
</blockquote>
<img src="/rookie/2022/07/30/kafka/kafka3/partitions-divide.png" class="" title="img.png">
<h1 id="3-分区消费者分配策略"><a href="#3-分区消费者分配策略" class="headerlink" title="3. 分区消费者分配策略"></a>3. 分区消费者分配策略</h1><p><em><strong>消费者配置项：partition.assignment.strategy</strong></em></p>
<h2 id="3-1-org-apache-kafka-clients-consumer-RangeAssignor"><a href="#3-1-org-apache-kafka-clients-consumer-RangeAssignor" class="headerlink" title="3.1 org.apache.kafka.clients.consumer.RangeAssignor"></a>3.1 org.apache.kafka.clients.consumer.RangeAssignor</h2><blockquote>
<p>以Topic为基础，将分区以分区号排序均匀分布给每个消费组中的消费者（按字母顺序排序），比如topic有7个分区，消费组中有3个消费者，<br>他会将分区数与消费者整除，余出的会加在前面的消费者身上，分区如下</p>
<ul>
<li>1号消费者：0,1,2</li>
<li>2号消费者：3,4</li>
<li>3号消费者：5,6</li>
</ul>
<p>这样问题就来了，当同一消费组订阅Topic过多，且不能整除的时候，前面的消费者会承担更多的分区消费，容易产生数据倾斜<br><strong>且这种策略，当一个消费者挂了之后，原属于该消费者的分区的消费任务会全部加到另一个分区上去，消费完成，后续的才会触发在再平衡</strong></p>
</blockquote>
<h2 id="3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor"><a href="#3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor" class="headerlink" title="3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor"></a>3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor</h2><blockquote>
<p>将一个消费组中的所有订阅的topic的分区汇在一起，按照消费者进行轮询分配，当消费组内所有消费者订阅Topic相同时，则这种分配时均匀的，如下：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有3个分区，则分配如下：</p>
<ul>
<li>消费者1：T1P0 T1P2 T2P1</li>
<li>消费者2：T1P1 T2P0 T2P2</li>
</ul>
<p>但当组内消费者订阅Topic不相同的时候，也会造成分配不均匀，例如：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有1个分区，且消费者2还订阅Topic3，有俩个分区则分配如下：</p>
<ul>
<li>消费者1：T1P0  </li>
<li>消费者2：T2P0 T3P0 T3P1</li>
</ul>
</blockquote>
<h2 id="3-3-org-apache-kafka-clients-consumer-StickyAssignor"><a href="#3-3-org-apache-kafka-clients-consumer-StickyAssignor" class="headerlink" title="3.3 org.apache.kafka.clients.consumer.StickyAssignor"></a>3.3 org.apache.kafka.clients.consumer.StickyAssignor</h2><blockquote>
<p>本策略有两个目标， 首先是要实现分区分配要尽可能地均匀，其次当发生分区再平衡发生时，分区的分配会尽可能的与上次的分配结果保持一致，目的是为了防止<br>分区的消费者发生变化，这有助于节约开销，也有助于避免消息重复消费的问题发生。需要注意的是，当以上两点发生冲突的时候，第一个目标是优先于第二个目标的,例如：<br>三个消费者C1，C2,C3,订阅了三个主题，且每个主题2个分区，</p>
<ul>
<li>C1：T1P0 T2P1</li>
<li>C2：T1P1 T3P0</li>
<li>C3：T2P0 T3P1  不一定按照这个排序哈</li>
</ul>
<p>当订阅不同时，例如<br>三个消费者，三个topic，分别有1,2,3个分区，消费者C1订阅了主题T0，消费者C2订阅了主题T0、T1，消费者C3订阅了主题T0、T1、T2分配如下</p>
<ul>
<li>C1:T0P0</li>
<li>C2:T1P0 T1P1</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p>当C1挂掉的时候会再平衡为</p>
<ul>
<li>C2:T1P0 T1P1 T0P0</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p><strong>RoundRobinAssignor和StickyAssignor非常重的要区别</strong></p>
<ul>
<li>StickyAssignor在消费组中每个消费者订阅不同topic时，能够使分配更加均匀</li>
<li>StickyAssignor某个消费者宕机后，再平衡时能够保留上次的，分配结果，只对宕机上的分区进行再分配，而RoundRobinAssignor不能保证，<br>  比如说，C1,C2,C3,在C1下线后，会将所有分区轮询C2，C3进行重新分配</li>
</ul>
</blockquote>
<h2 id="3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor"><a href="#3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor" class="headerlink" title="3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor"></a>3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor</h2><h2 id="3-5-自定义Assignor"><a href="#3-5-自定义Assignor" class="headerlink" title="3.5 自定义Assignor"></a>3.5 自定义Assignor</h2><blockquote>
<p>实现org.apache.kafka.clients.consumer.ConsumerPartitionAssignor接口</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerPartitionAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConsumerPartitionAssignor</span> <span class="keyword">implements</span> <span class="title class_">ConsumerPartitionAssignor</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GroupAssignment <span class="title function_">assign</span><span class="params">(Cluster metadata, GroupSubscription groupSubscription)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">name</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-6-消费者分区分配规则流程"><a href="#3-6-消费者分区分配规则流程" class="headerlink" title="3.6 消费者分区分配规则流程"></a>3.6 消费者分区分配规则流程</h2><img src="/rookie/2022/07/30/kafka/kafka3/consumer-partition-assignment.png" class="" title="img.png">


]]></content>
      <categories>
        <category>kafka</category>
        <category>进阶篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/rookie/2022/07/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<span id="more"></span>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（一）</title>
    <url>/rookie/2022/07/24/kafka/kafka1/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><blockquote>
<p>Kafka 是由 Linkedin 公司开发的， 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue）,同时是支持多分区、多副本的分布式消息流平台，适合大数据的存储以及计算</p>
</blockquote>
<h2 id="2、应用场景"><a href="#2、应用场景" class="headerlink" title="2、应用场景"></a>2、应用场景</h2><blockquote>
<p><strong>限流削峰</strong>：在非常高的并发下，防止导致服务系统崩溃，消息队列能帮忙服务顶住突发的访问压力，解决生产能力和消费能力不一致的问题</p>
</blockquote>
<blockquote>
<p><strong>服务解耦</strong>：解除不同服务之间的依赖关系，防止一端服务变更导致另一端服务需要同步变更或崩溃的问题，使修改更为灵活，维护与开发成本降低</p>
</blockquote>
<blockquote>
<p><strong>异步通信</strong>：允许将消息放入队列中不用立即处理，且生产者发送消息时也可选择异步或者同步发送</p>
</blockquote>
<h2 id="3、特点"><a href="#3、特点" class="headerlink" title="3、特点"></a>3、特点</h2><blockquote>
<p><strong>高吞吐、低延迟</strong>：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；<br><strong>高伸缩性</strong>：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；<br><strong>持久性、可靠性</strong>：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，<br>Zookeeper 我们知道它的数据能够持久存储；<br><strong>容错性</strong>：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；<br><strong>高并发</strong>：支持数千个客户端同时读写。</p>
</blockquote>
<h2 id="4、基本概念"><a href="#4、基本概念" class="headerlink" title="4、基本概念"></a>4、基本概念</h2><blockquote>
<p><strong>生产者（Producer）</strong>：向 Kafka 发布（写入）事件的客户端应用程序<br><strong>消费者（Consumer）</strong>：订阅（读取和处理）事件的客户端应用程序<br><strong>节点（Broker）</strong>：kafka所安装的服务器，负责存储和读取消息<br><strong>主题（Topic）</strong>：消息的主题，每条发布到队列中的消息都隶属一个主题<br><strong>分区（Partition）</strong>：可以为主题划定分区，存储在不同的节点，提高消息存储以及读取的速率<br><strong>消费者群组（Consumer Group）</strong>：包含一组消费者，topic的一个分区只会被同一消费组中的某一个消费者进行消费</p>
</blockquote>
<h2 id="5、对比"><a href="#5、对比" class="headerlink" title="5、对比"></a>5、对比</h2><img src="/rookie/2022/07/24/kafka/kafka1/kafka-compare.png" class="" title="img.png">  



]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka常见面试题以及答案整理</title>
    <url>/rookie/2022/08/01/kafka/kafka4/</url>
    <content><![CDATA[<h3 id="Kafka的用途有哪些？使用场景如何？"><a href="#Kafka的用途有哪些？使用场景如何？" class="headerlink" title="Kafka的用途有哪些？使用场景如何？"></a>Kafka的用途有哪些？使用场景如何？</h3><blockquote>
</blockquote>
<h3 id="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"><a href="#Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么" class="headerlink" title="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"></a>Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</h3><blockquote>
<p><strong>ISR</strong>：所有与leader副本保持一定程度同步的副本（包括leader副本在内），（In-Sync Replicas）<br><strong>OSR</strong>：与leader副本同步滞后过多或断开连接的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），<br>时间阈值由replica.lag.time.max.ms配置，默认30S<br><strong>AR</strong>：所有的副本列表统称AR（Assigned Replicas）<br><strong>ISR伸缩</strong>：leader副本负责维护和跟踪 ISR 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。<br>如果 OSR 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变</p>
</blockquote>
<h3 id="Kafka中的HW、LEO、LSO、LW等分别代表什么？"><a href="#Kafka中的HW、LEO、LSO、LW等分别代表什么？" class="headerlink" title="Kafka中的HW、LEO、LSO、LW等分别代表什么？"></a>Kafka中的HW、LEO、LSO、LW等分别代表什么？</h3><blockquote>
<p><strong>HW</strong>:High Watermark 高水位线，所有副本中最小的offset,即ISR中副本最小的LEO<br><strong>LEO</strong>:Log End Offset，每个副本当前日志文件中下一条待写入消息的offset，即最新的Offset+1，<br><strong>LSO</strong>:Last Stable Offset,与kafka 事务有关。对于未完成的事务而言，LSO的值等于事务中的第一条消息所在的位置（firstUnstableOffset）；对于已经完成的事务而言，它的值等同于HW相同<br><strong>LW</strong>:Low Watermark,AR集合中最小的LogStartOffset值。<br><strong>Log Start Offset</strong>：每个副本当前日志文件中写入消息的起始offset</p>
</blockquote>
<blockquote>
<p><strong>消费者配置参数：isolation.level</strong>,这个参数用来配置消费者事务的隔离级别。可选值“read_uncommitted”和“read_committed”，表示消费者所消费到<br>的位置，如果设置为“read_committed”，那么消费这就会忽略事务未提交的消息，即只能消费到LSO(LastStableOffset)的位置，<br>默认配置为”read_uncommitted”,即可以消费到HW（High Watermak）的位置。<br><strong>注：follower副本的事务隔离级别也为“read_uncommitted”，并且不可修改。</strong></p>
</blockquote>
<h3 id="Kafka中是怎么体现消息顺序性的？"><a href="#Kafka中是怎么体现消息顺序性的？" class="headerlink" title="Kafka中是怎么体现消息顺序性的？"></a>Kafka中是怎么体现消息顺序性的？</h3><blockquote>
<p><strong>一定条件下，消息单分区内有序</strong>  </p>
<ul>
<li>在kafka  1.x版本之前需要配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>  </li>
<li>在kafka  1.x版本后，未开启幂等性的情况下必须配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>，开启幂等性配置（默认开启）可配置<strong>max.in.flight.requests.per.connect&#x3D;5</strong>，<br> 最大为5，因为kafka服务器端会缓存producer5个request的元数据</li>
</ul>
</blockquote>
<h3 id="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h3><blockquote>
<p>拦截器-&gt;序列化器-&gt;分区器</p>
<ul>
<li><strong>拦截器</strong>：用于Client的定制化逻辑处理，比如说过滤不合规则的数据，补充修改消息内容等等，自定义拦截器可以通过实现ProducerInterceptor（生产者的拦截器）接口  </li>
<li><strong>序列化器</strong>： 序列化数据，防止数据丢失  </li>
<li><strong>分区器</strong>：按照一定规则，将数据划分到不同的分区，若未手动指定分区，则使用默认的分区策略，也可通过实现Partitioner实现自定义分区</li>
</ul>
</blockquote>
<h3 id="Kafka生产者客户端的整体结构是什么样子的？"><a href="#Kafka生产者客户端的整体结构是什么样子的？" class="headerlink" title="Kafka生产者客户端的整体结构是什么样子的？"></a>Kafka生产者客户端的整体结构是什么样子的？</h3><img src="/rookie/2022/08/01/kafka/kafka4/producer-design.png" class="" title="img.png">
<h3 id="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"><a href="#Kafka生产者客户端中使用了几个线程来处理？分别是什么？" class="headerlink" title="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"></a>Kafka生产者客户端中使用了几个线程来处理？分别是什么？</h3><blockquote>
<p>俩个，main线程和sender线程,具体作用详见上图</p>
</blockquote>
<h3 id="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"><a href="#Kafka的旧版Scala的消费者客户端的设计有什么缺陷？" class="headerlink" title="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"></a>Kafka的旧版Scala的消费者客户端的设计有什么缺陷？</h3><blockquote>
<p>老版本的 Consumer Group 把位移保存在 ZooKeeper 中,这种大吞吐量的写操作会极大地拖慢 ZooKeeper 集群的性能</p>
</blockquote>
<h3 id="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"><a href="#“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？" class="headerlink" title="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"></a>“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</h3><blockquote>
<p>一般来说如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区,但是可以通过继承AbstractPartitionAssignor<br>实现自定义消费策略，从而实现同一消费组内的任意消费者都可以消费订阅主题的所有分区，其实就是组内广播，</p>
</blockquote>
<h3 id="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1"><a href="#消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1" class="headerlink" title="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?"></a>消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</h3><blockquote>
<p>在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的。而在新消费者客户端中，消费位移存储在 Kafka 内部的主题__consumer_offsets 中。<br>当前消费者需要提交的消费位移是offset+1</p>
</blockquote>
<h3 id="有哪些情形会造成重复消费？"><a href="#有哪些情形会造成重复消费？" class="headerlink" title="有哪些情形会造成重复消费？"></a>有哪些情形会造成重复消费？</h3><blockquote>
<ul>
<li><p><strong>Rebalance</strong>:一个consumer正在消费一个分区的一条消息，还没有消费完，发生了rebalance(加入了一个consumer)，从而导致这条消息没有消费成功，rebalance后，另一个consumer又把这条消息消费一遍。</p>
</li>
<li><p><strong>消费者端手动提交</strong>:如果先消费消息，再更新offset位置，导致消息重复消费。</p>
</li>
<li><p><strong>消费者端自动提交</strong>:设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe() 则有可能部分offset没提交，下次重启会重复消费。</p>
</li>
<li><p><strong>生产者端</strong>:生产者因为业务问题导致的宕机，在重启之后可能数据会重发</p>
</li>
</ul>
</blockquote>
<h3 id="那些情景下会造成消息漏消费？"><a href="#那些情景下会造成消息漏消费？" class="headerlink" title="那些情景下会造成消息漏消费？"></a>那些情景下会造成消息漏消费？</h3><blockquote>
<ul>
<li><strong>自动提交</strong>:设置offset为自动定时提交，当offset被自动定时提交时，数据还在内存中未处理，此时刚好把线程kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</li>
<li><strong>生产者发送消息</strong>:<br>发送消息设置的是fire-and-forget（发后即忘），它只管往 Kafka 中发送消息而并不关心消息是否正确到达。不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。</li>
<li><strong>消费者端</strong>:<br>先提交位移，但是消息还没消费完就宕机了，造成了消息没有被消费。自动位移提交同理</li>
<li><strong>acks没有设置为all</strong>:<br>如果在broker还没把消息同步到其他broker的时候宕机了，那么消息将会丢失</li>
</ul>
</blockquote>
<h3 id="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"><a href="#KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？" class="headerlink" title="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"></a>KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</h3><img src="/rookie/2022/08/01/kafka/kafka4/multi-thread-consumer.png" class="" title="img.png">
<h3 id="简述消费者与消费组之间的关系"><a href="#简述消费者与消费组之间的关系" class="headerlink" title="简述消费者与消费组之间的关系"></a>简述消费者与消费组之间的关系</h3><blockquote>
<p>Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。<br>Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费</p>
</blockquote>
<h3 id="当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h3><blockquote>
<p>Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为&#x2F;tmp&#x2F;kafka-logs&#x2F;。<br>在 ZooKeeper 的&#x2F;brokers&#x2F;topics&#x2F;目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案</p>
</blockquote>
<h3 id="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h3><blockquote>
<p>可以增加，使用 kafka-topics 脚本，结合 –alter 参数来增加某个主题的分区数</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。<br>首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病的一个方面。<br>其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。<br>最后，Rebalance 实在是太慢了</p>
</blockquote>
<h3 id="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h3><blockquote>
<p>不支持，因为删除的分区中的消息不好处理。如果直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对的</p>
</blockquote>
<h3 id="创建topic时如何选择合适的分区数？"><a href="#创建topic时如何选择合适的分区数？" class="headerlink" title="创建topic时如何选择合适的分区数？"></a>创建topic时如何选择合适的分区数？</h3><blockquote>
<p>可以使用Kafka 本身提供的用于生产者性能测试的 kafka-producer- perf-test.sh 和用于消费者性能测试的 kafka-consumer-perf-test.sh来进行测试。<br>增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。<br>分区数的多少还会影响系统的可用性。如果分区数非常多，如果集群中的某个 broker 节点宕机，那么就会有大量的分区需要同时进行 leader 角色切换，这个切换的过程会耗费一笔可观的时间，并且在这个时间窗口内这些分区也会变得不可用。<br>分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间。</p>
</blockquote>
<h3 id="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"><a href="#Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？" class="headerlink" title="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"></a>Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？</h3><blockquote>
<p><strong>__consumer_offsets</strong>：作用是保存 Kafka 消费者的位移信息<br><strong>__transaction_state</strong>：用来存储事务日志消息</p>
</blockquote>
<h3 id="优先副本是什么？它有什么特殊的作用？"><a href="#优先副本是什么？它有什么特殊的作用？" class="headerlink" title="优先副本是什么？它有什么特殊的作用？"></a>优先副本是什么？它有什么特殊的作用？</h3><blockquote>
<p>所谓的优先副本是指在AR集合列表中的第一个副本。理想情况下，优先副本就是该分区的leader 副本，所以也可以称之为 preferred leader。<br>Kafka 要确保所有主题的优先副本在 Kafka 集群中均匀分布，这样就保证了所有分区的 leader 均衡分布。以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”</p>
</blockquote>
<h3 id="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"><a href="#Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理" class="headerlink" title="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"></a>Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</h3><blockquote>
<ul>
<li><strong>生产者的分区分配</strong>:是指为每条消息指定其所要发往的分区。可以编写一个具体的类实现org.apache.kafka.clients.producer.Partitioner接口。</li>
<li><strong>消费者中的分区分配</strong>:是指为消费者指定其可以消费消息的分区。Kafka 提供了消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。</li>
<li><strong>分区副本的分配</strong>:是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。kafka-topics.sh 脚本中提供了一个 replica-assignment 参数来手动指定分区副本的分配方案</li>
</ul>
</blockquote>
<h3 id="简述Kafka的日志目录结构"><a href="#简述Kafka的日志目录结构" class="headerlink" title="简述Kafka的日志目录结构"></a>简述Kafka的日志目录结构</h3><img src="/rookie/2022/08/01/kafka/kafka4/log-construct.png" class="" title="img.png">
<h3 id="Kafka中有那些索引文件？"><a href="#Kafka中有那些索引文件？" class="headerlink" title="Kafka中有那些索引文件？"></a>Kafka中有那些索引文件？</h3><blockquote>
<ul>
<li><strong>偏移量索引文件</strong>:用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置</li>
<li><strong>时间戳索引文件</strong>:则根据指定的时间戳（timestamp）来查找对应的偏移量信息。</li>
</ul>
</blockquote>
<h3 id="如果我指定了一个offset，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个offset，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个offset，Kafka怎么查找到对应的消息？"></a>如果我指定了一个offset，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka是通过seek() 方法来指定消费的，在执行seek() 方法之前要去执行一次poll()方法，等到分配到分区之后会去对应的分区的指定位置开始消费，如果指定的位置发生了越界，那么会根据auto.offset.reset 参数设置的情况进行消费。</p>
</blockquote>
<h3 id="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个timestamp，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"></a>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka提供了一个 offsetsForTimes() 方法，通过 timestamp 来查询与此对应的分区位置。offsetsForTimes() 方法的参数 timestampsToSearch 是一个 Map 类型，key 为待查询的分区，而 value 为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 OffsetAndTimestamp 中的 offset 和 timestamp 字段</p>
</blockquote>
<h3 id="聊一聊你对Kafka的Log-Retention的理解"><a href="#聊一聊你对Kafka的Log-Retention的理解" class="headerlink" title="聊一聊你对Kafka的Log Retention的理解"></a>聊一聊你对Kafka的Log Retention的理解</h3><blockquote>
<p><strong>日志删除：</strong> 配置服务端参数log.cleanup.policy:delete(默认就是delete)</p>
<ul>
<li><strong>基于时间：</strong> 日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）retentionMs， 可以通过 broker 端参数 log.retention.hours、log.retention.minutes 和 log.retention.ms 来配置，三个配置优先级依次提升。默认情况下只配置了 log.retention.hours 参数，其值为168，即为7天。<br>  删除日志分段时，首先会从 Log 对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上“.deleted”的后缀（当然也包括对应的索引文件）。最后交由一个以“delete-file”命名的延迟任务来删除这些以“.deleted”为后缀的文件，这个任务的延迟执行时间可以通过 file.delete.delay.ms 参数来调配，此参数的默认值为60000，即1分钟。</li>
<li><strong>基于大小：</strong> 日志删除任务会检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments）。<br>  retentionSize 可以通过 broker 端参数 log.retention.bytes 来配置，默认值为-1，表示无穷大。注意 log.retention.bytes 配置的是 Log 中所有日志文件的总大小，而不是单个日志分段（确切地说应该为 .log 日志文件）的大小。单个日志分段的大小由 broker 端参数 log.segment.bytes 来限制，默认值为1073741824，即 1GB</li>
<li><strong>基于日志偏移量：</strong> 这个无法配置，一般不关注，一般情况下日志文件的起始偏移量logStartOffset（logStartOffset值是整个 Log 对象对外可见消息的最小位移值）等于第一个日志分段的baseOffset，但是这并不是绝对的，logStartOffset的值可以通过DeleteRecordsRequest请求、日志的清理和截断等操作修改。</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">log.retention.hours=168 //7d</span><br><span class="line">log.retention.check.interval.ms=300000 //5min log过期检查时间间隔</span><br><span class="line">log.segment.bytes=1073741824 //1G</span><br><span class="line">log.cleaner.delete.retention.ms=86400000 // 1d 标记为deleted的segment的保留时间</span><br><span class="line">log.cleaner.backoff.ms=15000 //15s 清理线程扫描间隔</span><br></pre></td></tr></table></figure>
<h3 id="聊一聊你对Kafka的Log-Compaction的理解"><a href="#聊一聊你对Kafka的Log-Compaction的理解" class="headerlink" title="聊一聊你对Kafka的Log Compaction的理解"></a>聊一聊你对Kafka的Log Compaction的理解</h3><blockquote>
<p><strong>日志压缩：</strong> 配置服务端参数log.cleanup.policy:compact<br>Log Compaction 对于有相同 key 的不同 value 值，只保留最后一个版本。如果应用只关心 key 对应的最新 value 值，则可以开启 Kafka 的日志清理功能，Kafka 会定期将相同 key 的消息进行合并，只保留最新的 value 值，一般可用于用户信息存储等</p>
</blockquote>
<h3 id="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"><a href="#聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）" class="headerlink" title="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"></a>聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）</h3><blockquote>
<p><strong>页缓存：</strong> 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I&#x2F;O 的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问，基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。<br>此外，即使 Kafka 服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。  </p>
<p><strong>零拷贝：</strong> 除了消息顺序追加、页缓存等技术，Kafka 还使用零拷贝（Zero-Copy）技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对 Linux 操作系统而言，零拷贝技术依赖于底层的 sendfile() 方法实现。对应于 Java 语言，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法   </p>
</blockquote>
<blockquote>
<p>下图中左侧为传统方式，右侧为零拷贝，详细可见：<a href="https://developer.ibm.com/articles/j-zerocopy/">https://developer.ibm.com/articles/j-zerocopy/</a></p>
</blockquote>
<img src="/rookie/2022/08/01/kafka/kafka4/zero-copy.png" class="" title="img.png">
<h3 id="聊一聊Kafka的延时操作的原理"><a href="#聊一聊Kafka的延时操作的原理" class="headerlink" title="聊一聊Kafka的延时操作的原理"></a>聊一聊Kafka的延时操作的原理</h3><blockquote>
<p>Kafka 中有多种延时操作，比如延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。<br>延时操作创建之后会被加入延时操作管理器（DelayedOperationPurgatory）来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现的。</p>
</blockquote>
<h3 id="聊一聊Kafka控制器的作用"><a href="#聊一聊Kafka控制器的作用" class="headerlink" title="聊一聊Kafka控制器的作用"></a>聊一聊Kafka控制器的作用</h3><h3 id="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"><a href="#消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）" class="headerlink" title="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"></a>消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）</h3><h3 id="Kafka中的幂等是怎么实现的"><a href="#Kafka中的幂等是怎么实现的" class="headerlink" title="Kafka中的幂等是怎么实现的"></a>Kafka中的幂等是怎么实现的</h3><h3 id="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）"><a href="#Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）" class="headerlink" title="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）"></a>Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）</h3><h3 id="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h3><h3 id="失效副本是指什么？有那些应对措施？"><a href="#失效副本是指什么？有那些应对措施？" class="headerlink" title="失效副本是指什么？有那些应对措施？"></a>失效副本是指什么？有那些应对措施？</h3><h3 id="多副本下，各个副本中的HW和LEO的演变过程"><a href="#多副本下，各个副本中的HW和LEO的演变过程" class="headerlink" title="多副本下，各个副本中的HW和LEO的演变过程"></a>多副本下，各个副本中的HW和LEO的演变过程</h3><h3 id="为什么Kafka不支持读写分离？"><a href="#为什么Kafka不支持读写分离？" class="headerlink" title="为什么Kafka不支持读写分离？"></a>为什么Kafka不支持读写分离？</h3><h3 id="Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）"><a href="#Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）" class="headerlink" title="Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）"></a>Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</h3><h3 id="Kafka中怎么实现死信队列和重试队列？"><a href="#Kafka中怎么实现死信队列和重试队列？" class="headerlink" title="Kafka中怎么实现死信队列和重试队列？"></a>Kafka中怎么实现死信队列和重试队列？</h3><h3 id="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"><a href="#Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）" class="headerlink" title="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"></a>Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）</h3><h3 id="Kafka中怎么做消息审计？"><a href="#Kafka中怎么做消息审计？" class="headerlink" title="Kafka中怎么做消息审计？"></a>Kafka中怎么做消息审计？</h3><h3 id="Kafka中怎么做消息轨迹？"><a href="#Kafka中怎么做消息轨迹？" class="headerlink" title="Kafka中怎么做消息轨迹？"></a>Kafka中怎么做消息轨迹？</h3><h3 id="Kafka中有那些配置参数比较有意思？聊一聊你的看法"><a href="#Kafka中有那些配置参数比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些配置参数比较有意思？聊一聊你的看法"></a>Kafka中有那些配置参数比较有意思？聊一聊你的看法</h3><h3 id="Kafka中有那些命名比较有意思？聊一聊你的看法"><a href="#Kafka中有那些命名比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些命名比较有意思？聊一聊你的看法"></a>Kafka中有那些命名比较有意思？聊一聊你的看法</h3><h3 id="Kafka有哪些指标需要着重关注？"><a href="#Kafka有哪些指标需要着重关注？" class="headerlink" title="Kafka有哪些指标需要着重关注？"></a>Kafka有哪些指标需要着重关注？</h3><h3 id="怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同"><a href="#怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同" class="headerlink" title="怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)"></a>怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)</h3><h3 id="Kafka的那些设计让它有如此高的性能？"><a href="#Kafka的那些设计让它有如此高的性能？" class="headerlink" title="Kafka的那些设计让它有如此高的性能？"></a>Kafka的那些设计让它有如此高的性能？</h3><h3 id="Kafka有什么优缺点？"><a href="#Kafka有什么优缺点？" class="headerlink" title="Kafka有什么优缺点？"></a>Kafka有什么优缺点？</h3><h3 id="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"><a href="#还用过什么同质类的其它产品，与Kafka相比有什么优缺点？" class="headerlink" title="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"></a>还用过什么同质类的其它产品，与Kafka相比有什么优缺点？</h3><h3 id="为什么选择Kafka"><a href="#为什么选择Kafka" class="headerlink" title="为什么选择Kafka?"></a>为什么选择Kafka?</h3><h3 id="在使用Kafka的过程中遇到过什么困难？怎么解决的？"><a href="#在使用Kafka的过程中遇到过什么困难？怎么解决的？" class="headerlink" title="在使用Kafka的过程中遇到过什么困难？怎么解决的？"></a>在使用Kafka的过程中遇到过什么困难？怎么解决的？</h3><h3 id="怎么样才能确保Kafka极大程度上的可靠性？"><a href="#怎么样才能确保Kafka极大程度上的可靠性？" class="headerlink" title="怎么样才能确保Kafka极大程度上的可靠性？"></a>怎么样才能确保Kafka极大程度上的可靠性？</h3><h3 id="聊一聊你对Kafka生态的理解"><a href="#聊一聊你对Kafka生态的理解" class="headerlink" title="聊一聊你对Kafka生态的理解"></a>聊一聊你对Kafka生态的理解</h3>]]></content>
      <tags>
        <tag>kafka 面试题</tag>
      </tags>
  </entry>
</search>
