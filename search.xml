<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/rookie.github.io/2022/07/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<span id="more"></span>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（一）</title>
    <url>/rookie.github.io/2022/07/24/kafka/kafka1/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><blockquote>
<p>Kafka 是由 Linkedin 公司开发的， 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue）,同时是支持多分区、多副本的分布式消息流平台，适合大数据的存储以及计算</p>
</blockquote>
<h2 id="2、应用场景"><a href="#2、应用场景" class="headerlink" title="2、应用场景"></a>2、应用场景</h2><blockquote>
<p><strong>限流削峰</strong>：在非常高的并发下，防止导致服务系统崩溃，消息队列能帮忙服务顶住突发的访问压力，解决生产能力和消费能力不一致的问题</p>
</blockquote>
<blockquote>
<p><strong>服务解耦</strong>：解除不同服务之间的依赖关系，防止一端服务变更导致另一端服务需要同步变更或崩溃的问题，使修改更为灵活，维护与开发成本降低</p>
</blockquote>
<blockquote>
<p><strong>异步通信</strong>：允许将消息放入队列中不用立即处理，且生产者发送消息时也可选择异步或者同步发送</p>
</blockquote>
<h2 id="3、特点"><a href="#3、特点" class="headerlink" title="3、特点"></a>3、特点</h2><blockquote>
<p><strong>高吞吐、低延迟</strong>：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；<br><strong>高伸缩性</strong>：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；<br><strong>持久性、可靠性</strong>：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，<br>Zookeeper 我们知道它的数据能够持久存储；<br><strong>容错性</strong>：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；<br><strong>高并发</strong>：支持数千个客户端同时读写。</p>
</blockquote>
<h2 id="4、基本概念"><a href="#4、基本概念" class="headerlink" title="4、基本概念"></a>4、基本概念</h2><blockquote>
<p><strong>生产者（Producer）</strong>：向 Kafka 发布（写入）事件的客户端应用程序<br><strong>消费者（Consumer）</strong>：订阅（读取和处理）事件的客户端应用程序<br><strong>节点（Broker）</strong>：kafka所安装的服务器，负责存储和读取消息<br><strong>主题（Topic）</strong>：消息的主题，每条发布到队列中的消息都隶属一个主题<br><strong>分区（Partition）</strong>：可以为主题划定分区，存储在不同的节点，提高消息存储以及读取的速率<br><strong>消费者群组（Consumer Group）</strong>：包含一组消费者，topic的一个分区只会被同一消费组中的某一个消费者进行消费</p>
</blockquote>
<h2 id="5、对比"><a href="#5、对比" class="headerlink" title="5、对比"></a>5、对比</h2><img src="/rookie.github.io/2022/07/24/kafka/kafka1/kafka-compare.png" class="" title="img.png">  



]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka2</title>
    <url>/rookie.github.io/2022/07/25/kafka/kafka2/</url>
    <content><![CDATA[<h2 id="1-kafka配置详解"><a href="#1-kafka配置详解" class="headerlink" title="1. kafka配置详解"></a>1. kafka配置详解</h2><h3 id="1-1-broker配置"><a href="#1-1-broker配置" class="headerlink" title="1.1 broker配置"></a>1.1 broker配置</h3><ul>
<li><strong>broker.id</strong>：（必须配置）节点ID，必须全局唯一</li>
<li><strong>log.dir</strong>：（必须配置）日志存放目录，默认值（&#x2F;tmp&#x2F;kafka-logs），tmp目录会被系统定期清理</li>
<li><strong>zookeeper.connect</strong>：（必须配置）zookeeper连接</li>
<li><strong>auto.create.topics.enable</strong>：是否自动创建主题，默认为true</li>
<li><strong>auto.leader.rebalance.enable</strong>：分区leader自动负载均衡，默认true</li>
<li><strong>compression.type</strong>：压缩类型，可选值 (‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)</li>
</ul>
<h3 id="1-2-producer配置"><a href="#1-2-producer配置" class="headerlink" title="1.2 producer配置"></a>1.2 producer配置</h3><ul>
<li><strong>client.id</strong>：生产者客户端Id</li>
<li><strong>batch.size</strong>：批量发送数据大小，默认16K</li>
<li><strong>linger.ms</strong>：延迟时间，默认0</li>
<li><strong>buffer.memory</strong>：缓冲区大小，默认32M</li>
<li><strong>compression.type</strong>：消息压缩格式，默认none，可选none, gzip, snappy, lz4, or zstd</li>
<li><strong>acks</strong>：消息确认机制，默认all，即-1，可选[all, -1, 0, 1]，0-不需要回应，1-等leader落盘后回应，-1-所有副本落盘后回应</li>
<li><strong>partitioner.class</strong>：分区器类路径，默认DefaultPartitioner，还提供RoundRobinPartitioner，UniformStickyPartitioner</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
<li><strong>retries</strong>：重试次数，默认int最大值</li>
<li><strong>enable.idempotence</strong>：幂等性，默认true,根据&lt;pid,分区号，序列号&gt;去重</li>
<li><strong>max.in.flight.requests.per.connection</strong>：生产者在收到kafka响应前最大发送请求数，默认5</li>
<li><strong>transactional.id</strong>：事务ID，全局唯一，基于enable.idempotence</li>
</ul>
<h3 id="1-3-consume配置"><a href="#1-3-consume配置" class="headerlink" title="1.3 consume配置"></a>1.3 consume配置</h3><ul>
<li><strong>group.id</strong>：消费者所属的群组ID</li>
<li><strong>enable.auto.commit</strong>：自动提交，默认开启，一般关闭</li>
<li><strong>auto.offset.reset</strong>：有效值为“earliest”“latest”“none”,默认latest</li>
<li><strong>fetch.min.bytes</strong>：最小拉取字节数，默认1(B)，</li>
<li><strong>fetch.max.wait.mss</strong>：拉取最大等待时间数，默认500（ms），</li>
<li><strong>max-poll-records</strong>：一次请求最大拉取的消息条数，默认500</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
</ul>
<h2 id="2-常用命令"><a href="#2-常用命令" class="headerlink" title="2. 常用命令"></a>2. 常用命令</h2><h3 id="2-1-启动停止"><a href="#2-1-启动停止" class="headerlink" title="2.1 启动停止"></a>2.1 启动停止</h3><ul>
<li>.&#x2F;bin&#x2F;kafka-server-start.sh -daemon .&#x2F;config&#x2F;server.properties</li>
<li>.&#x2F;bin&#x2F;kafka-server-stop.sh</li>
</ul>
<h3 id="2-2-主题（kafka-topic-sh）"><a href="#2-2-主题（kafka-topic-sh）" class="headerlink" title="2.2 主题（kafka-topic.sh）"></a>2.2 主题（kafka-topic.sh）</h3><ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
<li>–create</li>
<li>–delete</li>
<li>–describe</li>
<li>–partitions</li>
<li>–replication-factor</li>
<li>–list</li>
</ul>
<h3 id="2-3-生产者（kafka-console-producer-sh）"><a href="#2-3-生产者（kafka-console-producer-sh）" class="headerlink" title="2.3 生产者（kafka-console-producer.sh）"></a>2.3 生产者（kafka-console-producer.sh）</h3><ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
</ul>
<h3 id="2-4-消费者（kafka-console-consumer-sh）"><a href="#2-4-消费者（kafka-console-consumer-sh）" class="headerlink" title="2.4 消费者（kafka-console-consumer.sh）"></a>2.4 消费者（kafka-console-consumer.sh）</h3><ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称 –from-beginning</li>
<li>–group 指定消费组</li>
</ul>
<h2 id="3-分区"><a href="#3-分区" class="headerlink" title="3. 分区"></a>3. 分区</h2><h3 id="3-1-默认分区规则"><a href="#3-1-默认分区规则" class="headerlink" title="3.1 默认分区规则"></a>3.1 默认分区规则</h3><ul>
<li>若发送时指定分区，则发送到指定的分区中</li>
<li>未指定分区，指定了Key，则Key的hashcode%分区数</li>
<li>均未指定，采取粘性规则，第一次随机选择分区，直到缓存满或者时间到发送完消息，下一次继续随机但不会选择上次使用的分区</li>
</ul>
<h3 id="3-2-自定义分区"><a href="#3-2-自定义分区" class="headerlink" title="3.2 自定义分区"></a>3.2 自定义分区</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义hash分区,实现Partitioner接口,重写partition方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartition</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes1, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取topic中partition数量</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="type">int</span> <span class="variable">partitionCount</span> <span class="operator">=</span> partitionInfoList.size();</span><br><span class="line">        <span class="comment">// 根据key的hash值计取模，计算出在哪个分区中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> Math.abs(String.valueOf(key).hashCode()) % partitionCount;</span><br><span class="line">        <span class="keyword">return</span> numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">kafkaProperties.put(<span class="string">&quot;partitioner.class&quot;</span>,<span class="string">&quot;com.pg.kafka.MyPartition&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
</search>
