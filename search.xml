<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/rookie.github.io/2022/07/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<span id="more"></span>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（一）</title>
    <url>/rookie.github.io/2022/07/24/kafka/kafka1/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><blockquote>
<p>Kafka 是由 Linkedin 公司开发的， 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue）,同时是支持多分区、多副本的分布式消息流平台，适合大数据的存储以及计算</p>
</blockquote>
<h2 id="2、应用场景"><a href="#2、应用场景" class="headerlink" title="2、应用场景"></a>2、应用场景</h2><blockquote>
<p><strong>限流削峰</strong>：在非常高的并发下，防止导致服务系统崩溃，消息队列能帮忙服务顶住突发的访问压力，解决生产能力和消费能力不一致的问题</p>
</blockquote>
<blockquote>
<p><strong>服务解耦</strong>：解除不同服务之间的依赖关系，防止一端服务变更导致另一端服务需要同步变更或崩溃的问题，使修改更为灵活，维护与开发成本降低</p>
</blockquote>
<blockquote>
<p><strong>异步通信</strong>：允许将消息放入队列中不用立即处理，且生产者发送消息时也可选择异步或者同步发送</p>
</blockquote>
<h2 id="3、特点"><a href="#3、特点" class="headerlink" title="3、特点"></a>3、特点</h2><blockquote>
<p><strong>高吞吐、低延迟</strong>：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；<br><strong>高伸缩性</strong>：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；<br><strong>持久性、可靠性</strong>：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，<br>Zookeeper 我们知道它的数据能够持久存储；<br><strong>容错性</strong>：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；<br><strong>高并发</strong>：支持数千个客户端同时读写。</p>
</blockquote>
<h2 id="4、基本概念"><a href="#4、基本概念" class="headerlink" title="4、基本概念"></a>4、基本概念</h2><blockquote>
<p><strong>生产者（Producer）</strong>：向 Kafka 发布（写入）事件的客户端应用程序<br><strong>消费者（Consumer）</strong>：订阅（读取和处理）事件的客户端应用程序<br><strong>节点（Broker）</strong>：kafka所安装的服务器，负责存储和读取消息<br><strong>主题（Topic）</strong>：消息的主题，每条发布到队列中的消息都隶属一个主题<br><strong>分区（Partition）</strong>：可以为主题划定分区，存储在不同的节点，提高消息存储以及读取的速率<br><strong>消费者群组（Consumer Group）</strong>：包含一组消费者，topic的一个分区只会被同一消费组中的某一个消费者进行消费</p>
</blockquote>
<h2 id="5、对比"><a href="#5、对比" class="headerlink" title="5、对比"></a>5、对比</h2><img src="/rookie.github.io/2022/07/24/kafka/kafka1/kafka-compare.png" class="" title="img.png">  



]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（二）</title>
    <url>/rookie.github.io/2022/07/25/kafka/kafka2/</url>
    <content><![CDATA[<h2 id="1-kafka配置详解"><a href="#1-kafka配置详解" class="headerlink" title="1. kafka配置详解"></a>1. kafka配置详解</h2><h3 id="1-1-broker配置"><a href="#1-1-broker配置" class="headerlink" title="1.1 broker配置"></a>1.1 broker配置</h3><blockquote>
<ul>
<li><strong>broker.id</strong>：（必须配置）节点ID，必须全局唯一</li>
<li><strong>log.dir</strong>：（必须配置）日志存放目录，默认值（&#x2F;tmp&#x2F;kafka-logs），tmp目录会被系统定期清理</li>
<li><strong>zookeeper.connect</strong>：（必须配置）zookeeper连接</li>
<li><strong>auto.create.topics.enable</strong>：是否自动创建主题，默认为true</li>
<li><strong>auto.leader.rebalance.enable</strong>：分区leader自动负载均衡，默认true</li>
<li><strong>compression.type</strong>：压缩类型，可选值 (‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)</li>
</ul>
</blockquote>
<h3 id="1-2-producer配置"><a href="#1-2-producer配置" class="headerlink" title="1.2 producer配置"></a>1.2 producer配置</h3><blockquote>
<ul>
<li><strong>client.id</strong>：生产者客户端Id</li>
<li><strong>batch.size</strong>：批量发送数据大小，默认16K</li>
<li><strong>linger.ms</strong>：延迟时间，默认0</li>
<li><strong>buffer.memory</strong>：缓冲区大小，默认32M</li>
<li><strong>compression.type</strong>：消息压缩格式，默认none，可选none, gzip, snappy, lz4, or zstd</li>
<li><strong>acks</strong>：消息确认机制，默认all，即-1，可选[all, -1, 0, 1]，0-不需要回应，1-等leader落盘后回应，-1-所有副本落盘后回应</li>
<li><strong>partitioner.class</strong>：分区器类路径，默认DefaultPartitioner，还提供RoundRobinPartitioner，UniformStickyPartitioner</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
<li><strong>retries</strong>：重试次数，默认int最大值</li>
<li><strong>enable.idempotence</strong>：幂等性，默认true,根据&lt;pid,分区号，序列号&gt;去重</li>
<li><strong>max.in.flight.requests.per.connection</strong>：生产者在收到kafka响应前最大发送请求数，默认5</li>
<li><strong>transactional.id</strong>：事务ID，全局唯一，基于enable.idempotence</li>
</ul>
</blockquote>
<h3 id="1-3-consume配置"><a href="#1-3-consume配置" class="headerlink" title="1.3 consume配置"></a>1.3 consume配置</h3><blockquote>
<ul>
<li><strong>group.id</strong>：消费者所属的群组ID</li>
<li><strong>enable.auto.commit</strong>：自动提交，默认开启，一般关闭</li>
<li><strong>auto.offset.reset</strong>：有效值为“earliest”“latest”“none”,默认latest</li>
<li><strong>fetch.min.bytes</strong>：最小拉取字节数，默认1(B)，</li>
<li><strong>fetch.max.wait.mss</strong>：拉取最大等待时间数，默认500（ms），</li>
<li><strong>max-poll-records</strong>：一次请求最大拉取的消息条数，默认500</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
</ul>
</blockquote>
<h2 id="2-常用命令"><a href="#2-常用命令" class="headerlink" title="2. 常用命令"></a>2. 常用命令</h2><h3 id="2-1-启动停止"><a href="#2-1-启动停止" class="headerlink" title="2.1 启动停止"></a>2.1 启动停止</h3><blockquote>
<ul>
<li>.&#x2F;bin&#x2F;kafka-server-start.sh -daemon .&#x2F;config&#x2F;server.properties</li>
<li>.&#x2F;bin&#x2F;kafka-server-stop.sh</li>
</ul>
</blockquote>
<h3 id="2-2-主题（kafka-topic-sh）"><a href="#2-2-主题（kafka-topic-sh）" class="headerlink" title="2.2 主题（kafka-topic.sh）"></a>2.2 主题（kafka-topic.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
<li>–create</li>
<li>–delete</li>
<li>–describe</li>
<li>–partitions</li>
<li>–replication-factor</li>
<li>–list</li>
</ul>
</blockquote>
<h3 id="2-3-生产者（kafka-console-producer-sh）"><a href="#2-3-生产者（kafka-console-producer-sh）" class="headerlink" title="2.3 生产者（kafka-console-producer.sh）"></a>2.3 生产者（kafka-console-producer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
</ul>
</blockquote>
<h3 id="2-4-消费者（kafka-console-consumer-sh）"><a href="#2-4-消费者（kafka-console-consumer-sh）" class="headerlink" title="2.4 消费者（kafka-console-consumer.sh）"></a>2.4 消费者（kafka-console-consumer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称 –from-beginning</li>
<li>–group 指定消费组</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-分区原来是这样子</title>
    <url>/rookie.github.io/2022/07/30/kafka/kafka3/</url>
    <content><![CDATA[<h1 id="1-分区器"><a href="#1-分区器" class="headerlink" title="1. 分区器"></a>1. 分区器</h1><blockquote>
<p><em><strong>broker配置项：partitioner.class</strong></em></p>
<ul>
<li>org.apache.kafka.clients.producer.internals.DefaultPartitioner</li>
<li>org.apache.kafka.clients.producer.RoundRobinPartitioner</li>
<li>org.apache.kafka.clients.producer.Partitioner</li>
</ul>
</blockquote>
<h2 id="1-1-默认分区器（DefaultPartitioner）"><a href="#1-1-默认分区器（DefaultPartitioner）" class="headerlink" title="1.1 默认分区器（DefaultPartitioner）"></a>1.1 默认分区器（DefaultPartitioner）</h2><blockquote>
<ul>
<li>若发送时指定分区，则发送到指定的分区中</li>
<li>未指定分区，指定了Key，则Key的hashcode%分区数</li>
<li>均未指定，采取粘性规则，第一次随机选择分区，直到缓存满或者时间到发送完消息，下一次继续随机但不会选择上次使用的分区</li>
</ul>
</blockquote>
<h2 id="1-2-RoundRobinPartitioner"><a href="#1-2-RoundRobinPartitioner" class="headerlink" title="1.2 RoundRobinPartitioner"></a>1.2 RoundRobinPartitioner</h2><blockquote>
<p>这种分区策略是一系列连续记录中的每条记录将被发送到不同的分区（无论是否提供’key’），直到我们用完分区并重新开始。注意：有一个已知问题会在创建新批次时导致分布不均</p>
</blockquote>
<h2 id="1-3-UniformStickyPartitioner"><a href="#1-3-UniformStickyPartitioner" class="headerlink" title="1.3 UniformStickyPartitioner"></a>1.3 UniformStickyPartitioner</h2><blockquote>
<p>此分区策略将尝试坚持一个分区（无论是否提供了“key”），直到batch.size已满或已满linger.ms</p>
</blockquote>
<h2 id="1-4-自定义分区"><a href="#1-4-自定义分区" class="headerlink" title="1.4 自定义分区"></a>1.4 自定义分区</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义hash分区,实现Partitioner接口,重写partition方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartition</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes1, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取topic中partition数量</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="type">int</span> <span class="variable">partitionCount</span> <span class="operator">=</span> partitionInfoList.size();</span><br><span class="line">        <span class="comment">// 根据key的hash值计取模，计算出在哪个分区中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> Math.abs(String.valueOf(key).hashCode()) % partitionCount;</span><br><span class="line">        <span class="keyword">return</span> numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">kafkaProperties.put(<span class="string">&quot;partitioner.class&quot;</span>,<span class="string">&quot;com.pg.kafka.MyPartition&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="2-分区节点分布策略"><a href="#2-分区节点分布策略" class="headerlink" title="2. 分区节点分布策略"></a>2. 分区节点分布策略</h1><p>创建topic,分配时，规则是尽量均匀将所有分区副本分布在各个broker上</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --create --replication-factor 3  --partitions 16 --topic test2</span><br></pre></td></tr></table></figure>
<p>查看topic信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe  --topic test2</span><br></pre></td></tr></table></figure>
<img src="/rookie.github.io/2022/07/30/kafka/kafka3/topic-describe.png" class="" title="img.png">
<blockquote>
<p>分配规则大致如下，借鉴网上教程的图</p>
</blockquote>
<img src="/rookie.github.io/2022/07/30/kafka/kafka3/partitions-divide.png" class="" title="img.png">
<h1 id="3-分区消费者分配策略"><a href="#3-分区消费者分配策略" class="headerlink" title="3. 分区消费者分配策略"></a>3. 分区消费者分配策略</h1><p><em><strong>消费者配置项：partition.assignment.strategy</strong></em></p>
<h2 id="3-1-org-apache-kafka-clients-consumer-RangeAssignor"><a href="#3-1-org-apache-kafka-clients-consumer-RangeAssignor" class="headerlink" title="3.1 org.apache.kafka.clients.consumer.RangeAssignor"></a>3.1 org.apache.kafka.clients.consumer.RangeAssignor</h2><blockquote>
<p>以Topic为基础，将分区以分区号排序均匀分布给每个消费组中的消费者（按字母顺序排序），比如topic有7个分区，消费组中有3个消费者，<br>他会将分区数与消费者整除，余出的会加在前面的消费者身上，分区如下</p>
<ul>
<li>1号消费者：0,1,2</li>
<li>2号消费者：3,4</li>
<li>3号消费者：5,6</li>
</ul>
<p>这样问题就来了，当同一消费组订阅Topic过多，且不能整除的时候，前面的消费者会承担更多的分区消费，容易产生数据倾斜<br><strong>且这种策略，当一个消费者挂了之后，原属于该消费者的分区的消费任务会全部加到另一个分区上去，消费完成，后续的才会触发在再平衡</strong></p>
</blockquote>
<h2 id="3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor"><a href="#3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor" class="headerlink" title="3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor"></a>3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor</h2><blockquote>
<p>将一个消费组中的所有订阅的topic的分区汇在一起，按照消费者进行轮询分配，当消费组内所有消费者订阅Topic相同时，则这种分配时均匀的，如下：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有3个分区，则分配如下：</p>
<ul>
<li>消费者1：T1P0 T1P2 T2P1</li>
<li>消费者2：T1P1 T2P0 T2P2</li>
</ul>
<p>但当组内消费者订阅Topic不相同的时候，也会造成分配不均匀，例如：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有1个分区，且消费者2还订阅Topic3，有俩个分区则分配如下：</p>
<ul>
<li>消费者1：T1P0  </li>
<li>消费者2：T2P0 T3P0 T3P1</li>
</ul>
</blockquote>
<h2 id="3-3-org-apache-kafka-clients-consumer-StickyAssignor"><a href="#3-3-org-apache-kafka-clients-consumer-StickyAssignor" class="headerlink" title="3.3 org.apache.kafka.clients.consumer.StickyAssignor"></a>3.3 org.apache.kafka.clients.consumer.StickyAssignor</h2><blockquote>
<p>本策略有两个目标， 首先是要实现分区分配要尽可能地均匀，其次当发生分区再平衡发生时，分区的分配会尽可能的与上次的分配结果保持一致，目的是为了防止<br>分区的消费者发生变化，这有助于节约开销，也有助于避免消息重复消费的问题发生。需要注意的是，当以上两点发生冲突的时候，第一个目标是优先于第二个目标的,例如：<br>三个消费者C1，C2,C3,订阅了三个主题，且每个主题2个分区，</p>
<ul>
<li>C1：T1P0 T2P1</li>
<li>C2：T1P1 T3P0</li>
<li>C3：T2P0 T3P1  不一定按照这个排序哈</li>
</ul>
<p>当订阅不同时，例如<br>三个消费者，三个topic，分别有1,2,3个分区，消费者C1订阅了主题T0，消费者C2订阅了主题T0、T1，消费者C3订阅了主题T0、T1、T2分配如下</p>
<ul>
<li>C1:T0P0</li>
<li>C2:T1P0 T1P1</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p>当C1挂掉的时候会再平衡为</p>
<ul>
<li>C2:T1P0 T1P1 T0P0</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p><strong>RoundRobinAssignor和StickyAssignor非常重的要区别</strong></p>
<ul>
<li>StickyAssignor在消费组中每个消费者订阅不同topic时，能够使分配更加均匀</li>
<li>StickyAssignor某个消费者宕机后，再平衡时能够保留上次的，分配结果，只对宕机上的分区进行再分配，而RoundRobinAssignor不能保证，<br>  比如说，C1,C2,C3,在C1下线后，会将所有分区轮询C2，C3进行重新分配</li>
</ul>
</blockquote>
<h2 id="3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor"><a href="#3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor" class="headerlink" title="3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor"></a>3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor</h2><h2 id="3-5-自定义Assignor"><a href="#3-5-自定义Assignor" class="headerlink" title="3.5 自定义Assignor"></a>3.5 自定义Assignor</h2><blockquote>
<p>实现org.apache.kafka.clients.consumer.ConsumerPartitionAssignor接口</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerPartitionAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConsumerPartitionAssignor</span> <span class="keyword">implements</span> <span class="title class_">ConsumerPartitionAssignor</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GroupAssignment <span class="title function_">assign</span><span class="params">(Cluster metadata, GroupSubscription groupSubscription)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">name</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-6-消费者分区分配规则流程"><a href="#3-6-消费者分区分配规则流程" class="headerlink" title="3.6 消费者分区分配规则流程"></a>3.6 消费者分区分配规则流程</h2><img src="/rookie.github.io/2022/07/30/kafka/kafka3/consumer-partition-assignment.png" class="" title="img.png">


]]></content>
      <categories>
        <category>kafka</category>
        <category>进阶篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
</search>
