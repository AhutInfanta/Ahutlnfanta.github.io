<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/rookie/2022/07/24/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<span id="more"></span>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（一）</title>
    <url>/rookie/2022/07/24/kafka/kafka1/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><blockquote>
<p>Kafka 是由 Linkedin 公司开发的， 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue）,同时是支持多分区、多副本的分布式消息流平台，适合大数据的存储以及计算</p>
</blockquote>
<h2 id="2、应用场景"><a href="#2、应用场景" class="headerlink" title="2、应用场景"></a>2、应用场景</h2><blockquote>
<p><strong>限流削峰</strong>：在非常高的并发下，防止导致服务系统崩溃，消息队列能帮忙服务顶住突发的访问压力，解决生产能力和消费能力不一致的问题</p>
</blockquote>
<blockquote>
<p><strong>服务解耦</strong>：解除不同服务之间的依赖关系，防止一端服务变更导致另一端服务需要同步变更或崩溃的问题，使修改更为灵活，维护与开发成本降低</p>
</blockquote>
<blockquote>
<p><strong>异步通信</strong>：允许将消息放入队列中不用立即处理，且生产者发送消息时也可选择异步或者同步发送</p>
</blockquote>
<h2 id="3、特点"><a href="#3、特点" class="headerlink" title="3、特点"></a>3、特点</h2><blockquote>
<p><strong>高吞吐、低延迟</strong>：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；<br><strong>高伸缩性</strong>：每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中；<br><strong>持久性、可靠性</strong>：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，<br>Zookeeper 我们知道它的数据能够持久存储；<br><strong>容错性</strong>：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；<br><strong>高并发</strong>：支持数千个客户端同时读写。</p>
</blockquote>
<h2 id="4、基本概念"><a href="#4、基本概念" class="headerlink" title="4、基本概念"></a>4、基本概念</h2><blockquote>
<p><strong>生产者（Producer）</strong>：向 Kafka 发布（写入）事件的客户端应用程序<br><strong>消费者（Consumer）</strong>：订阅（读取和处理）事件的客户端应用程序<br><strong>节点（Broker）</strong>：kafka所安装的服务器，负责存储和读取消息<br><strong>主题（Topic）</strong>：消息的主题，每条发布到队列中的消息都隶属一个主题<br><strong>分区（Partition）</strong>：可以为主题划定分区，存储在不同的节点，提高消息存储以及读取的速率<br><strong>消费者群组（Consumer Group）</strong>：包含一组消费者，topic的一个分区只会被同一消费组中的某一个消费者进行消费</p>
</blockquote>
<h2 id="5、对比"><a href="#5、对比" class="headerlink" title="5、对比"></a>5、对比</h2><img src="/rookie/2022/07/24/kafka/kafka1/kafka-compare.png" class="" title="img.png">  



]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka概述（二）</title>
    <url>/rookie/2022/07/25/kafka/kafka2/</url>
    <content><![CDATA[<h2 id="1-kafka配置详解"><a href="#1-kafka配置详解" class="headerlink" title="1. kafka配置详解"></a>1. kafka配置详解</h2><h3 id="1-1-broker配置"><a href="#1-1-broker配置" class="headerlink" title="1.1 broker配置"></a>1.1 broker配置</h3><blockquote>
<ul>
<li><strong>broker.id</strong>：（必须配置）节点ID，必须全局唯一</li>
<li><strong>log.dir</strong>：（必须配置）日志存放目录，默认值（&#x2F;tmp&#x2F;kafka-logs），tmp目录会被系统定期清理</li>
<li><strong>zookeeper.connect</strong>：（必须配置）zookeeper连接</li>
<li><strong>auto.create.topics.enable</strong>：是否自动创建主题，默认为true</li>
<li><strong>auto.leader.rebalance.enable</strong>：分区leader自动负载均衡，默认true</li>
<li><strong>compression.type</strong>：压缩类型，可选值 (‘gzip’, ‘snappy’, ‘lz4’, ‘zstd’)</li>
</ul>
</blockquote>
<h3 id="1-2-producer配置"><a href="#1-2-producer配置" class="headerlink" title="1.2 producer配置"></a>1.2 producer配置</h3><blockquote>
<ul>
<li><strong>client.id</strong>：生产者客户端Id</li>
<li><strong>batch.size</strong>：批量发送数据大小，默认16K</li>
<li><strong>linger.ms</strong>：延迟时间，默认0</li>
<li><strong>buffer.memory</strong>：缓冲区大小，默认32M</li>
<li><strong>compression.type</strong>：消息压缩格式，默认none，可选none, gzip, snappy, lz4, or zstd</li>
<li><strong>acks</strong>：消息确认机制，默认all，即-1，可选[all, -1, 0, 1]，0-不需要回应，1-等leader落盘后回应，-1-所有副本落盘后回应</li>
<li><strong>partitioner.class</strong>：分区器类路径，默认DefaultPartitioner，还提供RoundRobinPartitioner，UniformStickyPartitioner</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
<li><strong>retries</strong>：重试次数，默认int最大值</li>
<li><strong>enable.idempotence</strong>：幂等性，默认true,根据&lt;pid,分区号，序列号&gt;去重</li>
<li><strong>max.in.flight.requests.per.connection</strong>：生产者在收到kafka响应前最大发送请求数，默认5</li>
<li><strong>transactional.id</strong>：事务ID，全局唯一，基于enable.idempotence</li>
</ul>
</blockquote>
<h3 id="1-3-consume配置"><a href="#1-3-consume配置" class="headerlink" title="1.3 consume配置"></a>1.3 consume配置</h3><blockquote>
<ul>
<li><strong>group.id</strong>：消费者所属的群组ID</li>
<li><strong>enable.auto.commit</strong>：自动提交，默认开启，一般关闭</li>
<li><strong>auto.offset.reset</strong>：有效值为“earliest”“latest”“none”,默认latest</li>
<li><strong>fetch.min.bytes</strong>：最小拉取字节数，默认1(B)，</li>
<li><strong>fetch.max.wait.mss</strong>：拉取最大等待时间数，默认500（ms），</li>
<li><strong>max-poll-records</strong>：一次请求最大拉取的消息条数，默认500</li>
<li><strong>key.serializer</strong>：key的序列化器</li>
<li><strong>value.serializer</strong>：value的序列化器</li>
<li><strong>bootstrap.servers</strong>：kafka地址</li>
</ul>
</blockquote>
<h2 id="2-常用命令"><a href="#2-常用命令" class="headerlink" title="2. 常用命令"></a>2. 常用命令</h2><h3 id="2-1-启动停止"><a href="#2-1-启动停止" class="headerlink" title="2.1 启动停止"></a>2.1 启动停止</h3><blockquote>
<ul>
<li>.&#x2F;bin&#x2F;kafka-server-start.sh -daemon .&#x2F;config&#x2F;server.properties</li>
<li>.&#x2F;bin&#x2F;kafka-server-stop.sh</li>
</ul>
</blockquote>
<h3 id="2-2-主题（kafka-topic-sh）"><a href="#2-2-主题（kafka-topic-sh）" class="headerlink" title="2.2 主题（kafka-topic.sh）"></a>2.2 主题（kafka-topic.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
<li>–create</li>
<li>–delete</li>
<li>–describe</li>
<li>–partitions</li>
<li>–replication-factor</li>
<li>–list</li>
</ul>
</blockquote>
<h3 id="2-3-生产者（kafka-console-producer-sh）"><a href="#2-3-生产者（kafka-console-producer-sh）" class="headerlink" title="2.3 生产者（kafka-console-producer.sh）"></a>2.3 生产者（kafka-console-producer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称</li>
</ul>
</blockquote>
<h3 id="2-4-消费者（kafka-console-consumer-sh）"><a href="#2-4-消费者（kafka-console-consumer-sh）" class="headerlink" title="2.4 消费者（kafka-console-consumer.sh）"></a>2.4 消费者（kafka-console-consumer.sh）</h3><blockquote>
<ul>
<li>–bootstrap-server IP:PORT(多个用逗号分隔)</li>
<li>–topic 主题名称 –from-beginning</li>
<li>–group 指定消费组</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>kafka</category>
        <category>基础篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka-分区原来是这样子</title>
    <url>/rookie/2022/07/30/kafka/kafka3/</url>
    <content><![CDATA[<h1 id="1-分区器"><a href="#1-分区器" class="headerlink" title="1. 分区器"></a>1. 分区器</h1><blockquote>
<p><em><strong>broker配置项：partitioner.class</strong></em></p>
<ul>
<li>org.apache.kafka.clients.producer.internals.DefaultPartitioner</li>
<li>org.apache.kafka.clients.producer.RoundRobinPartitioner</li>
<li>org.apache.kafka.clients.producer.Partitioner</li>
</ul>
</blockquote>
<h2 id="1-1-默认分区器（DefaultPartitioner）"><a href="#1-1-默认分区器（DefaultPartitioner）" class="headerlink" title="1.1 默认分区器（DefaultPartitioner）"></a>1.1 默认分区器（DefaultPartitioner）</h2><blockquote>
<ul>
<li>若发送时指定分区，则发送到指定的分区中</li>
<li>未指定分区，指定了Key，则Key的hashcode%分区数</li>
<li>均未指定，采取粘性规则，第一次随机选择分区，直到缓存满或者时间到发送完消息，下一次继续随机但不会选择上次使用的分区</li>
</ul>
</blockquote>
<h2 id="1-2-RoundRobinPartitioner"><a href="#1-2-RoundRobinPartitioner" class="headerlink" title="1.2 RoundRobinPartitioner"></a>1.2 RoundRobinPartitioner</h2><blockquote>
<p>这种分区策略是一系列连续记录中的每条记录将被发送到不同的分区（无论是否提供’key’），直到我们用完分区并重新开始。注意：有一个已知问题会在创建新批次时导致分布不均</p>
</blockquote>
<h2 id="1-3-UniformStickyPartitioner"><a href="#1-3-UniformStickyPartitioner" class="headerlink" title="1.3 UniformStickyPartitioner"></a>1.3 UniformStickyPartitioner</h2><blockquote>
<p>此分区策略将尝试坚持一个分区（无论是否提供了“key”），直到batch.size已满或已满linger.ms</p>
</blockquote>
<h2 id="1-4-自定义分区"><a href="#1-4-自定义分区" class="headerlink" title="1.4 自定义分区"></a>1.4 自定义分区</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.PartitionInfo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义hash分区,实现Partitioner接口,重写partition方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyPartition</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes1, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取topic中partition数量</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">        <span class="type">int</span> <span class="variable">partitionCount</span> <span class="operator">=</span> partitionInfoList.size();</span><br><span class="line">        <span class="comment">// 根据key的hash值计取模，计算出在哪个分区中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> Math.abs(String.valueOf(key).hashCode()) % partitionCount;</span><br><span class="line">        <span class="keyword">return</span> numPartitions;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">kafkaProperties.put(<span class="string">&quot;partitioner.class&quot;</span>,<span class="string">&quot;com.pg.kafka.MyPartition&quot;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="2-分区节点分布策略"><a href="#2-分区节点分布策略" class="headerlink" title="2. 分区节点分布策略"></a>2. 分区节点分布策略</h1><p>创建topic,分配时，规则是尽量均匀将所有分区副本分布在各个broker上</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --create --replication-factor 3  --partitions 16 --topic test2</span><br></pre></td></tr></table></figure>
<p>查看topic信息</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --describe  --topic test2</span><br></pre></td></tr></table></figure>
<img src="/rookie/2022/07/30/kafka/kafka3/topic-describe.png" class="" title="img.png">
<blockquote>
<p>分配规则大致如下，借鉴网上教程的图</p>
</blockquote>
<img src="/rookie/2022/07/30/kafka/kafka3/partitions-divide.png" class="" title="img.png">
<h1 id="3-分区消费者分配策略"><a href="#3-分区消费者分配策略" class="headerlink" title="3. 分区消费者分配策略"></a>3. 分区消费者分配策略</h1><p><em><strong>消费者配置项：partition.assignment.strategy</strong></em></p>
<h2 id="3-1-org-apache-kafka-clients-consumer-RangeAssignor"><a href="#3-1-org-apache-kafka-clients-consumer-RangeAssignor" class="headerlink" title="3.1 org.apache.kafka.clients.consumer.RangeAssignor"></a>3.1 org.apache.kafka.clients.consumer.RangeAssignor</h2><blockquote>
<p>以Topic为基础，将分区以分区号排序均匀分布给每个消费组中的消费者（按字母顺序排序），比如topic有7个分区，消费组中有3个消费者，<br>他会将分区数与消费者整除，余出的会加在前面的消费者身上，分区如下</p>
<ul>
<li>1号消费者：0,1,2</li>
<li>2号消费者：3,4</li>
<li>3号消费者：5,6</li>
</ul>
<p>这样问题就来了，当同一消费组订阅Topic过多，且不能整除的时候，前面的消费者会承担更多的分区消费，容易产生数据倾斜<br><strong>且这种策略，当一个消费者挂了之后，原属于该消费者的分区的消费任务会全部加到另一个分区上去，消费完成，后续的才会触发在再平衡</strong></p>
</blockquote>
<h2 id="3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor"><a href="#3-2-org-apache-kafka-clients-consumer-RoundRobinAssignor" class="headerlink" title="3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor"></a>3.2 org.apache.kafka.clients.consumer.RoundRobinAssignor</h2><blockquote>
<p>将一个消费组中的所有订阅的topic的分区汇在一起，按照消费者进行轮询分配，当消费组内所有消费者订阅Topic相同时，则这种分配时均匀的，如下：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有3个分区，则分配如下：</p>
<ul>
<li>消费者1：T1P0 T1P2 T2P1</li>
<li>消费者2：T1P1 T2P0 T2P2</li>
</ul>
<p>但当组内消费者订阅Topic不相同的时候，也会造成分配不均匀，例如：<br>消费者1，消费者2均订阅Topic1，Topic2，俩个Topic均有1个分区，且消费者2还订阅Topic3，有俩个分区则分配如下：</p>
<ul>
<li>消费者1：T1P0  </li>
<li>消费者2：T2P0 T3P0 T3P1</li>
</ul>
</blockquote>
<h2 id="3-3-org-apache-kafka-clients-consumer-StickyAssignor"><a href="#3-3-org-apache-kafka-clients-consumer-StickyAssignor" class="headerlink" title="3.3 org.apache.kafka.clients.consumer.StickyAssignor"></a>3.3 org.apache.kafka.clients.consumer.StickyAssignor</h2><blockquote>
<p>本策略有两个目标， 首先是要实现分区分配要尽可能地均匀，其次当发生分区再平衡发生时，分区的分配会尽可能的与上次的分配结果保持一致，目的是为了防止<br>分区的消费者发生变化，这有助于节约开销，也有助于避免消息重复消费的问题发生。需要注意的是，当以上两点发生冲突的时候，第一个目标是优先于第二个目标的,例如：<br>三个消费者C1，C2,C3,订阅了三个主题，且每个主题2个分区，</p>
<ul>
<li>C1：T1P0 T2P1</li>
<li>C2：T1P1 T3P0</li>
<li>C3：T2P0 T3P1  不一定按照这个排序哈</li>
</ul>
<p>当订阅不同时，例如<br>三个消费者，三个topic，分别有1,2,3个分区，消费者C1订阅了主题T0，消费者C2订阅了主题T0、T1，消费者C3订阅了主题T0、T1、T2分配如下</p>
<ul>
<li>C1:T0P0</li>
<li>C2:T1P0 T1P1</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p>当C1挂掉的时候会再平衡为</p>
<ul>
<li>C2:T1P0 T1P1 T0P0</li>
<li>C3:T2P0 T2P1 T2P2</li>
</ul>
<p><strong>RoundRobinAssignor和StickyAssignor非常重的要区别</strong></p>
<ul>
<li>StickyAssignor在消费组中每个消费者订阅不同topic时，能够使分配更加均匀</li>
<li>StickyAssignor某个消费者宕机后，再平衡时能够保留上次的，分配结果，只对宕机上的分区进行再分配，而RoundRobinAssignor不能保证，<br>  比如说，C1,C2,C3,在C1下线后，会将所有分区轮询C2，C3进行重新分配</li>
</ul>
</blockquote>
<h2 id="3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor"><a href="#3-4-org-apache-kafka-clients-consumer-CooperativeStickyAssignor" class="headerlink" title="3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor"></a>3.4 org.apache.kafka.clients.consumer.CooperativeStickyAssignor</h2><h2 id="3-5-自定义Assignor"><a href="#3-5-自定义Assignor" class="headerlink" title="3.5 自定义Assignor"></a>3.5 自定义Assignor</h2><blockquote>
<p>实现org.apache.kafka.clients.consumer.ConsumerPartitionAssignor接口</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerPartitionAssignor;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyConsumerPartitionAssignor</span> <span class="keyword">implements</span> <span class="title class_">ConsumerPartitionAssignor</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GroupAssignment <span class="title function_">assign</span><span class="params">(Cluster metadata, GroupSubscription groupSubscription)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">name</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="3-6-消费者分区分配规则流程"><a href="#3-6-消费者分区分配规则流程" class="headerlink" title="3.6 消费者分区分配规则流程"></a>3.6 消费者分区分配规则流程</h2><img src="/rookie/2022/07/30/kafka/kafka3/consumer-partition-assignment.png" class="" title="img.png">


]]></content>
      <categories>
        <category>kafka</category>
        <category>进阶篇</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka常见面试题以及答案整理</title>
    <url>/rookie/2022/08/01/kafka/kafka4/</url>
    <content><![CDATA[<h3 id="Kafka的用途有哪些？使用场景如何？"><a href="#Kafka的用途有哪些？使用场景如何？" class="headerlink" title="Kafka的用途有哪些？使用场景如何？"></a>Kafka的用途有哪些？使用场景如何？</h3><blockquote>
</blockquote>
<h3 id="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"><a href="#Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么" class="headerlink" title="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"></a>Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</h3><blockquote>
<p><strong>ISR</strong>：所有与leader副本保持一定程度同步的副本（包括leader副本在内），（In-Sync Replicas）<br><strong>OSR</strong>：与leader副本同步滞后过多或断开连接的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），<br>时间阈值由replica.lag.time.max.ms配置，默认30S<br><strong>AR</strong>：所有的副本列表统称AR（Assigned Replicas）<br><strong>ISR伸缩</strong>：leader副本负责维护和跟踪 ISR 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。<br>如果 OSR 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变</p>
</blockquote>
<h3 id="Kafka中的HW、LEO、LSO、LW等分别代表什么？"><a href="#Kafka中的HW、LEO、LSO、LW等分别代表什么？" class="headerlink" title="Kafka中的HW、LEO、LSO、LW等分别代表什么？"></a>Kafka中的HW、LEO、LSO、LW等分别代表什么？</h3><blockquote>
<p><strong>HW</strong>:High Watermark 高水位线，所有副本中最小的offset,即ISR中副本最小的LEO<br><strong>LEO</strong>:Log End Offset，每个副本当前日志文件中下一条待写入消息的offset，即最新的Offset+1，<br><strong>LSO</strong>:Last Stable Offset,与kafka 事务有关。对于未完成的事务而言，LSO的值等于事务中的第一条消息所在的位置（firstUnstableOffset）；对于已经完成的事务而言，它的值等同于HW相同<br><strong>LW</strong>:Low Watermark,AR集合中最小的LogStartOffset值。<br><strong>Log Start Offset</strong>：每个副本当前日志文件中写入消息的起始offset</p>
</blockquote>
<blockquote>
<p><strong>消费者配置参数：isolation.level</strong>,这个参数用来配置消费者事务的隔离级别。可选值“read_uncommitted”和“read_committed”，表示消费者所消费到<br>的位置，如果设置为“read_committed”，那么消费这就会忽略事务未提交的消息，即只能消费到LSO(LastStableOffset)的位置，<br>默认配置为”read_uncommitted”,即可以消费到HW（High Watermak）的位置。<br><strong>注：follower副本的事务隔离级别也为“read_uncommitted”，并且不可修改。</strong></p>
</blockquote>
<h3 id="Kafka中是怎么体现消息顺序性的？"><a href="#Kafka中是怎么体现消息顺序性的？" class="headerlink" title="Kafka中是怎么体现消息顺序性的？"></a>Kafka中是怎么体现消息顺序性的？</h3><blockquote>
<p><strong>一定条件下，消息单分区内有序</strong>  </p>
<ul>
<li>在kafka  1.x版本之前需要配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>  </li>
<li>在kafka  1.x版本后，未开启幂等性的情况下必须配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>，开启幂等性配置（默认开启）可配置<strong>max.in.flight.requests.per.connect&#x3D;5</strong>，<br> 最大为5，因为kafka服务器端会缓存producer5个request的元数据</li>
</ul>
</blockquote>
<h3 id="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h3><blockquote>
<p>拦截器-&gt;序列化器-&gt;分区器</p>
<ul>
<li><strong>拦截器</strong>：用于Client的定制化逻辑处理，比如说过滤不合规则的数据，补充修改消息内容等等，自定义拦截器可以通过实现ProducerInterceptor（生产者的拦截器）接口  </li>
<li><strong>序列化器</strong>： 序列化数据，防止数据丢失  </li>
<li><strong>分区器</strong>：按照一定规则，将数据划分到不同的分区，若未手动指定分区，则使用默认的分区策略，也可通过实现Partitioner实现自定义分区</li>
</ul>
</blockquote>
<h3 id="Kafka生产者客户端的整体结构是什么样子的？"><a href="#Kafka生产者客户端的整体结构是什么样子的？" class="headerlink" title="Kafka生产者客户端的整体结构是什么样子的？"></a>Kafka生产者客户端的整体结构是什么样子的？</h3><img src="/rookie/2022/08/01/kafka/kafka4/producer-design.png" class="" title="img.png">
<h3 id="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"><a href="#Kafka生产者客户端中使用了几个线程来处理？分别是什么？" class="headerlink" title="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"></a>Kafka生产者客户端中使用了几个线程来处理？分别是什么？</h3><blockquote>
<p>俩个，main线程和sender线程,具体作用详见上图</p>
</blockquote>
<h3 id="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"><a href="#Kafka的旧版Scala的消费者客户端的设计有什么缺陷？" class="headerlink" title="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"></a>Kafka的旧版Scala的消费者客户端的设计有什么缺陷？</h3><blockquote>
<p>老版本的 Consumer Group 把位移保存在 ZooKeeper 中,这种大吞吐量的写操作会极大地拖慢 ZooKeeper 集群的性能</p>
</blockquote>
<h3 id="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"><a href="#“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？" class="headerlink" title="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"></a>“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</h3><blockquote>
<p>一般来说如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区,但是可以通过继承AbstractPartitionAssignor<br>实现自定义消费策略，从而实现同一消费组内的任意消费者都可以消费订阅主题的所有分区，其实就是组内广播，</p>
</blockquote>
<h3 id="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1"><a href="#消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1" class="headerlink" title="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?"></a>消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</h3><blockquote>
<p>在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的。而在新消费者客户端中，消费位移存储在 Kafka 内部的主题__consumer_offsets 中。<br>当前消费者需要提交的消费位移是offset+1</p>
</blockquote>
<h3 id="有哪些情形会造成重复消费？"><a href="#有哪些情形会造成重复消费？" class="headerlink" title="有哪些情形会造成重复消费？"></a>有哪些情形会造成重复消费？</h3><blockquote>
<ul>
<li><p><strong>Rebalance</strong>:一个consumer正在消费一个分区的一条消息，还没有消费完，发生了rebalance(加入了一个consumer)，从而导致这条消息没有消费成功，rebalance后，另一个consumer又把这条消息消费一遍。</p>
</li>
<li><p><strong>消费者端手动提交</strong>:如果先消费消息，再更新offset位置，导致消息重复消费。</p>
</li>
<li><p><strong>消费者端自动提交</strong>:设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe() 则有可能部分offset没提交，下次重启会重复消费。</p>
</li>
<li><p><strong>生产者端</strong>:生产者因为业务问题导致的宕机，在重启之后可能数据会重发</p>
</li>
</ul>
</blockquote>
<h3 id="那些情景下会造成消息漏消费？"><a href="#那些情景下会造成消息漏消费？" class="headerlink" title="那些情景下会造成消息漏消费？"></a>那些情景下会造成消息漏消费？</h3><blockquote>
<ul>
<li><strong>自动提交</strong>:设置offset为自动定时提交，当offset被自动定时提交时，数据还在内存中未处理，此时刚好把线程kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</li>
<li><strong>生产者发送消息</strong>:<br>发送消息设置的是fire-and-forget（发后即忘），它只管往 Kafka 中发送消息而并不关心消息是否正确到达。不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。</li>
<li><strong>消费者端</strong>:<br>先提交位移，但是消息还没消费完就宕机了，造成了消息没有被消费。自动位移提交同理</li>
<li><strong>acks没有设置为all</strong>:<br>如果在broker还没把消息同步到其他broker的时候宕机了，那么消息将会丢失</li>
</ul>
</blockquote>
<h3 id="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"><a href="#KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？" class="headerlink" title="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"></a>KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</h3><img src="/rookie/2022/08/01/kafka/kafka4/multi-thread-consumer.png" class="" title="img.png">
<h3 id="简述消费者与消费组之间的关系"><a href="#简述消费者与消费组之间的关系" class="headerlink" title="简述消费者与消费组之间的关系"></a>简述消费者与消费组之间的关系</h3><blockquote>
<p>Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。<br>Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费</p>
</blockquote>
<h3 id="当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h3><blockquote>
<p>Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为&#x2F;tmp&#x2F;kafka-logs&#x2F;。<br>在 ZooKeeper 的&#x2F;brokers&#x2F;topics&#x2F;目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案</p>
</blockquote>
<h3 id="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h3><blockquote>
<p>可以增加，使用 kafka-topics 脚本，结合 –alter 参数来增加某个主题的分区数</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。<br>首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病的一个方面。<br>其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。<br>最后，Rebalance 实在是太慢了</p>
</blockquote>
<h3 id="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h3><blockquote>
<p>不支持，因为删除的分区中的消息不好处理。如果直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对的</p>
</blockquote>
<h3 id="创建topic时如何选择合适的分区数？"><a href="#创建topic时如何选择合适的分区数？" class="headerlink" title="创建topic时如何选择合适的分区数？"></a>创建topic时如何选择合适的分区数？</h3><blockquote>
<p>可以使用Kafka 本身提供的用于生产者性能测试的 kafka-producer- perf-test.sh 和用于消费者性能测试的 kafka-consumer-perf-test.sh来进行测试。<br>增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。<br>分区数的多少还会影响系统的可用性。如果分区数非常多，如果集群中的某个 broker 节点宕机，那么就会有大量的分区需要同时进行 leader 角色切换，这个切换的过程会耗费一笔可观的时间，并且在这个时间窗口内这些分区也会变得不可用。<br>分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间。</p>
</blockquote>
<h3 id="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"><a href="#Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？" class="headerlink" title="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"></a>Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？</h3><blockquote>
<p><strong>__consumer_offsets</strong>：作用是保存 Kafka 消费者的位移信息<br><strong>__transaction_state</strong>：用来存储事务日志消息</p>
</blockquote>
<h3 id="优先副本是什么？它有什么特殊的作用？"><a href="#优先副本是什么？它有什么特殊的作用？" class="headerlink" title="优先副本是什么？它有什么特殊的作用？"></a>优先副本是什么？它有什么特殊的作用？</h3><blockquote>
<p>所谓的优先副本是指在AR集合列表中的第一个副本。理想情况下，优先副本就是该分区的leader 副本，所以也可以称之为 preferred leader。<br>Kafka 要确保所有主题的优先副本在 Kafka 集群中均匀分布，这样就保证了所有分区的 leader 均衡分布。以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”</p>
</blockquote>
<h3 id="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"><a href="#Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理" class="headerlink" title="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"></a>Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</h3><blockquote>
<ul>
<li><strong>生产者的分区分配</strong>:是指为每条消息指定其所要发往的分区。可以编写一个具体的类实现org.apache.kafka.clients.producer.Partitioner接口。</li>
<li><strong>消费者中的分区分配</strong>:是指为消费者指定其可以消费消息的分区。Kafka 提供了消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。</li>
<li><strong>分区副本的分配</strong>:是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。kafka-topics.sh 脚本中提供了一个 replica-assignment 参数来手动指定分区副本的分配方案</li>
</ul>
</blockquote>
<h3 id="简述Kafka的日志目录结构"><a href="#简述Kafka的日志目录结构" class="headerlink" title="简述Kafka的日志目录结构"></a>简述Kafka的日志目录结构</h3><img src="/rookie/2022/08/01/kafka/kafka4/log-construct.png" class="" title="img.png">
<h3 id="Kafka中有那些索引文件？"><a href="#Kafka中有那些索引文件？" class="headerlink" title="Kafka中有那些索引文件？"></a>Kafka中有那些索引文件？</h3><blockquote>
<ul>
<li><strong>偏移量索引文件</strong>:用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置</li>
<li><strong>时间戳索引文件</strong>:则根据指定的时间戳（timestamp）来查找对应的偏移量信息。</li>
</ul>
</blockquote>
<h3 id="如果我指定了一个offset，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个offset，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个offset，Kafka怎么查找到对应的消息？"></a>如果我指定了一个offset，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka是通过seek() 方法来指定消费的，在执行seek() 方法之前要去执行一次poll()方法，等到分配到分区之后会去对应的分区的指定位置开始消费，如果指定的位置发生了越界，那么会根据auto.offset.reset 参数设置的情况进行消费。</p>
</blockquote>
<h3 id="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个timestamp，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"></a>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka提供了一个 offsetsForTimes() 方法，通过 timestamp 来查询与此对应的分区位置。offsetsForTimes() 方法的参数 timestampsToSearch 是一个 Map 类型，key 为待查询的分区，而 value 为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 OffsetAndTimestamp 中的 offset 和 timestamp 字段</p>
</blockquote>
<h3 id="聊一聊你对Kafka的Log-Retention的理解"><a href="#聊一聊你对Kafka的Log-Retention的理解" class="headerlink" title="聊一聊你对Kafka的Log Retention的理解"></a>聊一聊你对Kafka的Log Retention的理解</h3><blockquote>
<p><strong>日志删除：</strong> 配置服务端参数log.cleanup.policy:delete(默认就是delete)</p>
<ul>
<li><strong>基于时间：</strong> 日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）retentionMs， 可以通过 broker 端参数 log.retention.hours、log.retention.minutes 和 log.retention.ms 来配置，三个配置优先级依次提升。默认情况下只配置了 log.retention.hours 参数，其值为168，即为7天。<br>  删除日志分段时，首先会从 Log 对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上“.deleted”的后缀（当然也包括对应的索引文件）。最后交由一个以“delete-file”命名的延迟任务来删除这些以“.deleted”为后缀的文件，这个任务的延迟执行时间可以通过 file.delete.delay.ms 参数来调配，此参数的默认值为60000，即1分钟。</li>
<li><strong>基于大小：</strong> 日志删除任务会检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments）。<br>  retentionSize 可以通过 broker 端参数 log.retention.bytes 来配置，默认值为-1，表示无穷大。注意 log.retention.bytes 配置的是 Log 中所有日志文件的总大小，而不是单个日志分段（确切地说应该为 .log 日志文件）的大小。单个日志分段的大小由 broker 端参数 log.segment.bytes 来限制，默认值为1073741824，即 1GB</li>
<li><strong>基于日志偏移量：</strong> 这个无法配置，一般不关注，一般情况下日志文件的起始偏移量logStartOffset（logStartOffset值是整个 Log 对象对外可见消息的最小位移值）等于第一个日志分段的baseOffset，但是这并不是绝对的，logStartOffset的值可以通过DeleteRecordsRequest请求、日志的清理和截断等操作修改。</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">log.retention.hours=168 //7d</span><br><span class="line">log.retention.check.interval.ms=300000 //5min log过期检查时间间隔</span><br><span class="line">log.segment.bytes=1073741824 //1G</span><br><span class="line">log.cleaner.delete.retention.ms=86400000 // 1d 标记为deleted的segment的保留时间</span><br><span class="line">log.cleaner.backoff.ms=15000 //15s 清理线程扫描间隔</span><br></pre></td></tr></table></figure>
<h3 id="聊一聊你对Kafka的Log-Compaction的理解"><a href="#聊一聊你对Kafka的Log-Compaction的理解" class="headerlink" title="聊一聊你对Kafka的Log Compaction的理解"></a>聊一聊你对Kafka的Log Compaction的理解</h3><blockquote>
<p><strong>日志压缩：</strong> 配置服务端参数log.cleanup.policy:compact<br>Log Compaction 对于有相同 key 的不同 value 值，只保留最后一个版本。如果应用只关心 key 对应的最新 value 值，则可以开启 Kafka 的日志清理功能，Kafka 会定期将相同 key 的消息进行合并，只保留最新的 value 值，一般可用于用户信息存储等</p>
</blockquote>
<h3 id="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"><a href="#聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）" class="headerlink" title="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"></a>聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）</h3><blockquote>
<p><strong>页缓存：</strong> 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I&#x2F;O 的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问，基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。<br>此外，即使 Kafka 服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。  </p>
<p><strong>零拷贝：</strong> 除了消息顺序追加、页缓存等技术，Kafka 还使用零拷贝（Zero-Copy）技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对 Linux 操作系统而言，零拷贝技术依赖于底层的 sendfile() 方法实现。对应于 Java 语言，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法   </p>
</blockquote>
<blockquote>
<p>下图中左侧为传统方式，右侧为零拷贝，详细可见：<a href="https://developer.ibm.com/articles/j-zerocopy/">https://developer.ibm.com/articles/j-zerocopy/</a></p>
</blockquote>
<img src="/rookie/2022/08/01/kafka/kafka4/zero-copy.png" class="" title="img.png">
<h3 id="聊一聊Kafka的延时操作的原理"><a href="#聊一聊Kafka的延时操作的原理" class="headerlink" title="聊一聊Kafka的延时操作的原理"></a>聊一聊Kafka的延时操作的原理</h3><blockquote>
<p>Kafka 中有多种延时操作，比如延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。<br>延时操作创建之后会被加入延时操作管理器（DelayedOperationPurgatory）来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现的。</p>
</blockquote>
<h3 id="聊一聊Kafka控制器的作用"><a href="#聊一聊Kafka控制器的作用" class="headerlink" title="聊一聊Kafka控制器的作用"></a>聊一聊Kafka控制器的作用</h3><blockquote>
<p><strong>controller选举：</strong> kafka集群在创建时，会在Zookeeper中创建临时节点 <KafkaZkChroot>&#x2F;controller,创建成功的那个broker为此次的controller,<br>其他的broker会对该控制器节点创建watch对象，监听该节点的变更，当控制器失效后，其他broker会进行抢注，当选新的controller  </p>
<p><strong>controller作用：</strong>  </p>
<ul>
<li>_主题管理_： 主题的创建、删除、修改分区；kafka-topics 脚本相关后台操作基本上都是由controller帮我们完成的</li>
<li>_分区重新分配_：kafka-reassign-partitions 脚本提供的对已有主题分区进行细粒度的分配功能</li>
<li>_Preferred 领导者选举_：当某个broker节点下线重新上线后，该broker节点上的所有分区副本均为Follower，会使分区Leader分布不均匀，这个可以协调Leader</li>
<li>_broker管理_： 自动检测broker的新增、宕机，依赖于利用Watch 机制检查 ZooKeeper 的 &#x2F;brokers&#x2F;ids 节点下的子节点数量变更，因为每个节点在启动后都会在<br>此节点下创建临时节点；</li>
<li>_存储集群数据_：向其他 Broker 提供数据服务。控制器上保存了最全的集群元数据信息，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据</li>
</ul>
</blockquote>
<h3 id="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"><a href="#消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）" class="headerlink" title="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"></a>消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）</h3><ul>
<li><strong><em>名词解释</em></strong><blockquote>
<p><strong>消费者协调器（ConsumerCoordinator）：</strong> 位于消费者客户端的组件，负责与GroupCoordinator通信<br><strong>消费组协调器（GroupCoordinator:）</strong> 位于kafka服务端，用于管理消费组的组件</p>
</blockquote>
</li>
<li><strong><em>什么时候会发生消费者再均衡？</em></strong><blockquote>
<ol>
<li>有新的消费者加入消费组或者宕机下线（不一定真的宕机，有可能只是长时间未与GroupCoordinator发送心跳，默认45秒就被判定掉线）</li>
<li>消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了 unsubscrible() 方法取消对某些主题的订阅</li>
<li>消费组所对应的 GroupCoorinator 节点发生了变更</li>
<li>消费组内所订阅的任一主题或者主题的分区数量发生变化。</li>
</ol>
</blockquote>
</li>
<li><strong><em>消费者消费过程</em></strong><blockquote>
<ol>
<li>FIND_COORDINATOR:确定消费者组对应的GroupCoordinator所在broker，并创建相互通信的网络连接，若连接不正常，就需要向集群中的负载最小的节点发送 FindCoordinatorRequest 请求来查找对应的 GroupCoordinator。  </li>
<li>JOIN_GROUP:消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。且会选择出一个消费者的Leader，并选出大多消费者支持的分区副本分配策略</li>
<li>SYNC_GROUP：消费者Leader将根据阶段二选出分配策略，实施具体的分配方案，并将方案通过GroupCoordinator同步给各个消费者</li>
<li>HEARTBEAT：消费者通过向GroupCoordinator发送心跳来维护自己的活跃性，默认每3秒一次，45秒超时，且心跳和消费是俩个独立的线程</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="Kafka中的幂等是怎么实现的"><a href="#Kafka中的幂等是怎么实现的" class="headerlink" title="Kafka中的幂等是怎么实现的"></a>Kafka中的幂等是怎么实现的</h3><blockquote>
<p>Kafka为此引入了producerId（简称 PID）和序列号（sequence number）这两个概念,每个生产者实例在初始化的时候会被分配一个PID（用户无感知，可以日志文件里查看），<br>对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将 &lt;PID，分区&gt; 对应的序列号的值加1，为每一对 &lt;PID，分区&gt; 维护一个序列号，<br>当出现乱序时，生产者会抛出 OutOfOrderSequenceException</p>
</blockquote>
<h3 id="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）"><a href="#Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）" class="headerlink" title="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）"></a>Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）</h3><blockquote>
<p>kafka事务是以幂等性为前提，生产者配置一个transactionalId而生效的；每个transactionalId和PID相对应<br>每次发送数据给&lt;Topic, Partition&gt;前，需要先向事务协调器发送AddPartitionsToTxnRequest，事务协调器会将该&lt;Transaction, Topic, Partition&gt;存于__transaction_state内，并将其状态置为BEGIN。</p>
<p>在处理完 AddOffsetsToTxnRequest 之后，生产者还会发送 TxnOffsetCommitRequest 请求给 GroupCoordinator，从而将本次事务中包含的消费位移信息 offsets 存储到主题 __consumer_offsets 中</p>
<p>一旦上述数据写入操作完成，应用程序必须调用KafkaProducer的commitTransaction方法或者abortTransaction方法以结束当前事务。无论调用 commitTransaction() 方法还是 abortTransaction() 方法，生产者都会向 TransactionCoordinator 发送 EndTxnRequest 请求。<br>TransactionCoordinator 在收到 EndTxnRequest 请求后会执行如下操作：</p>
<p>将 PREPARE_COMMIT 或 PREPARE_ABORT 消息写入主题 __transaction_state<br>通过 WriteTxnMarkersRequest 请求将 COMMIT 或 ABORT 信息写入用户所使用的普通主题和 __consumer_offsets<br>将 COMPLETE_COMMIT 或 COMPLETE_ABORT 信息写入内部主题 __transaction_state标明该事务结束<br>在消费端有一个参数isolation.level，设置为“read_committed”，表示消费端应用不可以看到尚未提交的事务内的消息。如果生产者开启事务并向某个分区值发送3条消息 msg1、msg2 和 msg3，在执行 commitTransaction() 或 abortTransaction() 方法前，设置为“read_committed”的消费端应用是消费不到这些消息的，不过在 KafkaConsumer 内部会缓存这些消息，直到生产者执行 commitTransaction() 方法之后它才能将这些消息推送给消费端应用。反之，如果生产者执行了 abortTransaction() 方法，那么 KafkaConsumer 会将这些缓存的消息丢弃而不推送给消费端应用。</p>
</blockquote>
<h3 id="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h3><blockquote>
</blockquote>
<h3 id="失效副本是指什么？有那些应对措施？"><a href="#失效副本是指什么？有那些应对措施？" class="headerlink" title="失效副本是指什么？有那些应对措施？"></a>失效副本是指什么？有那些应对措施？</h3><blockquote>
<p>正常情况下，分区的所有副本都处于 ISR 集合中，但是难免会有异常情况发生，从而某些副本被剥离出 ISR 集合中。在 ISR 集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即 under-replicated 分区</p>
<p>一般有这几种情况会导致副本失效：</p>
<ul>
<li>follower 副本进程卡住，在一段时间内根本没有向 leader 副本发起同步请求，比如频繁的 Full GC。</li>
<li>follower 副本进程同步过慢，在一段时间内都无法追赶上 leader 副本，比如 I&#x2F;O 开销过大。</li>
<li>如果通过工具增加了副本因子，那么新增加的副本在赶上 leader 副本之前也都是处于失效状态的。</li>
<li>如果一个 follower 副本由于某些原因（比如宕机）而下线，之后又上线，在追赶上 leader 副本之前也处于失效状态</li>
</ul>
</blockquote>
<h3 id="多副本下，各个副本中的HW和LEO的演变过程"><a href="#多副本下，各个副本中的HW和LEO的演变过程" class="headerlink" title="多副本下，各个副本中的HW和LEO的演变过程"></a>多副本下，各个副本中的HW和LEO的演变过程</h3><h3 id="为什么Kafka不支持读写分离？"><a href="#为什么Kafka不支持读写分离？" class="headerlink" title="为什么Kafka不支持读写分离？"></a>为什么Kafka不支持读写分离？</h3><blockquote>
<p><strong>数据一致性问题:</strong> 数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。<br><strong>延时问题:</strong> 数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。  </p>
</blockquote>
<p>对于Kafka来说，必要性不是很高，因为在Kafka集群中，如果存在多个副本，经过合理的配置，可以让leader副本均匀的分布在各个broker上面，使每个 broker 上的读写负载都是一样的。</p>
<h3 id="Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）"><a href="#Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）" class="headerlink" title="Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）"></a>Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</h3><blockquote>
<p><strong>HW</strong>: HW 是 High Watermark 的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个 offset 之前的消息。<br>分区 ISR 集合中的每个副本都会维护自身的 LEO，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息</p>
<p><strong>LeaderEpoch:</strong> 代表 leader 的纪元信息（epoch），初始值为0。每当 leader 变更一次，leader epoch 的值就会加1<br>leader epoch 的值就会加1，相当于为 leader 增设了一个版本号。每个副本中还会增设一个矢量 &lt;LeaderEpoch &#x3D;&gt; StartOffset&gt;，<br>其中 StartOffset 表示当前 LeaderEpoch 下写入的第一条消息的偏移量。</p>
</blockquote>
<p>假设有两个节点A和B，B是leader节点，里面的数据如图：</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch1.png" class="" title="img.png">  
<p>A发生重启，之后A不是先忙着截断日志而是先发送OffsetsForLeaderEpochRequest请求给B，B作为目前的leader在收到请求之后会返回当前的LEO（LogEndOffset，注意图中LE0和LEO的不同），与请求对应的响应为OffsetsForLeaderEpochResponse。如果 A 中的 LeaderEpoch（假设为 LE_A）和 B 中的不相同，那么 B 此时会查找 LeaderEpoch 为 LE_A+1 对应的 StartOffset 并返回给 A</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch2.png" class="" title="img_1.png">  
<p>如上图所示，A 在收到2之后发现和目前的 LEO 相同，也就不需要截断日志了，以此来保护数据的完整性。</p>
<p>再如，之后 B 发生了宕机，A 成为新的 leader，那么对应的 LE&#x3D;0 也变成了 LE&#x3D;1，对应的消息 m2 此时就得到了保留。后续的消息都可以以 LE1 为 LeaderEpoch 陆续追加到 A 中。这个时候A就会有两个LE，第二LE所记录的Offset从2开始。如果B恢复了，那么就会从A中获取到LE+1的Offset为2的值返回给B。</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch3.png" class="" title="img_2.png">  
<p>再来看看LE如何解决数据不一致的问题：<br>当前 A 为 leader，B 为 follower，A 中有2条消息 m1 和 m2，而 B 中有1条消息 m1。假设 A 和 B 同时“挂掉”，然后 B 第一个恢复过来并成为新的 leader。</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch4.png" class="" title="img_3.png">  
<p>之后 B 写入消息 m3，并将 LEO 和 HW 更新至2，如下图所示。注意此时的 LeaderEpoch 已经从 LE0 增至 LE1 了。</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch5.png" class="" title="img_4.png">  
<p>紧接着 A 也恢复过来成为 follower 并向 B 发送 OffsetsForLeaderEpochRequest 请求，此时 A 的 LeaderEpoch 为 LE0。B 根据 LE0 查询到对应的 offset 为1并返回给 A，A 就截断日志并删除了消息 m2，如下图所示。之后 A 发送 FetchRequest 至 B 请求来同步数据，最终A和B中都有两条消息 m1 和 m3，HW 和 LEO都为2，并且 LeaderEpoch 都为 LE1，如此便解决了数据不一致的问题。</p>
<img src="/rookie/2022/08/01/kafka/kafka4/leaderEpoch6.png" class="" title="img_5.png">  

<h3 id="Kafka中怎么实现死信队列和重试队列？"><a href="#Kafka中怎么实现死信队列和重试队列？" class="headerlink" title="Kafka中怎么实现死信队列和重试队列？"></a>Kafka中怎么实现死信队列和重试队列？</h3><h3 id="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"><a href="#Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）" class="headerlink" title="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"></a>Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）</h3><h3 id="Kafka中怎么做消息审计？"><a href="#Kafka中怎么做消息审计？" class="headerlink" title="Kafka中怎么做消息审计？"></a>Kafka中怎么做消息审计？</h3><blockquote>
<p>消息审计是指在消息生产、存储和消费的整个过程之间对消息个数及延迟的审计，以此来检测是否有数据丢失、是否有数据重复、端到端的延迟又是多少等内容。</p>
<p>目前与消息审计有关的产品也有多个，比如 Chaperone（Uber）、Confluent Control Center、Kafka Monitor（LinkedIn），它们主要通过在消息体（value 字段）或在消息头（headers 字段）中内嵌消息对应的时间戳 timestamp 或全局的唯一标识 ID（或者是两者兼备）来实现消息的审计功能。</p>
<p>内嵌 timestamp 的方式主要是设置一个审计的时间间隔 time_bucket_interval（可以自定义设置几秒或几分钟），根据这个 time_bucket_interval 和消息所属的 timestamp 来计算相应的时间桶（time_bucket）。</p>
<p>内嵌 ID 的方式就更加容易理解了，对于每一条消息都会被分配一个全局唯一标识 ID。如果主题和相应的分区固定，则可以为每个分区设置一个全局的 ID。当有消息发送时，首先获取对应的 ID，然后内嵌到消息中，最后才将它发送到 broker 中。消费者进行消费审计时，可以判断出哪条消息丢失、哪条消息重复。</p>
</blockquote>
<h3 id="Kafka中怎么做消息轨迹？"><a href="#Kafka中怎么做消息轨迹？" class="headerlink" title="Kafka中怎么做消息轨迹？"></a>Kafka中怎么做消息轨迹？</h3><blockquote>
<p>消息轨迹指的是一条消息从生产者发出，经由 broker 存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路信息。生产者、broker、消费者这3个角色在处理消息的过程中都会在链路中增加相应的信息，将这些信息汇聚、处理之后就可以查询任意消息的状态，进而为生产环境中的故障排除提供强有力的数据支持。</p>
<p>对消息轨迹而言，最常见的实现方式是封装客户端，在保证正常生产消费的同时添加相应的轨迹信息埋点逻辑。无论生产，还是消费，在执行之后都会有相应的轨迹信息，我们需要将这些信息保存起来。</p>
<p>我们同样可以将轨迹信息保存到 Kafka 的某个主题中，比如下图中的主题 trace_topic。</p>
</blockquote>
<img src="/rookie/2022/08/01/kafka/kafka4/messageTrace.png" class="" title="img.png">
<h3 id="Kafka中有那些配置参数比较有意思？聊一聊你的看法"><a href="#Kafka中有那些配置参数比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些配置参数比较有意思？聊一聊你的看法"></a>Kafka中有那些配置参数比较有意思？聊一聊你的看法</h3><h3 id="Kafka中有那些命名比较有意思？聊一聊你的看法"><a href="#Kafka中有那些命名比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些命名比较有意思？聊一聊你的看法"></a>Kafka中有那些命名比较有意思？聊一聊你的看法</h3><h3 id="Kafka有哪些指标需要着重关注？"><a href="#Kafka有哪些指标需要着重关注？" class="headerlink" title="Kafka有哪些指标需要着重关注？"></a>Kafka有哪些指标需要着重关注？</h3><blockquote>
<p>比较重要的 Broker 端 JMX 指标：</p>
<ul>
<li>BytesIn&#x2F;BytesOut：即 Broker 端每秒入站和出站字节数。你要确保这组值不要接近你的网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。</li>
<li>NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减负。</li>
<li>RequestHandlerAvgIdlePercent：即 I&#x2F;O 线程池线程平均的空闲比例。同样地，如果该值长期小于 30%，你需要调整 I&#x2F;O 线程池的数量，或者减少 Broker 端的负载。</li>
<li>UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失。因此，这是一个非常重要的 JMX 指标。</li>
<li>ISRShrink&#x2F;ISRExpand：即 ISR 收缩和扩容的频次指标。如果你的环境中出现 ISR 中副本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出 ISR 的原因，并采取适当的措施。</li>
<li>ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下，Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。</li>
</ul>
</blockquote>
<h3 id="怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同"><a href="#怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同" class="headerlink" title="怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)"></a>怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)</h3><blockquote>
<p>如果消费者客户端的 isolation.level 参数配置为“read_uncommitted”（默认）,它对应的 Lag 等于HW – ConsumerOffset 的值，其中 ConsumerOffset 表示当前的消费位移。</p>
<p>如果这个参数配置为“read_committed”，那么就要引入 LSO 来进行计算了。LSO 是 LastStableOffset 的缩写,它对应的 Lag 等于 LSO – ConsumerOffset 的值。</p>
<ul>
<li>首先通过 DescribeGroupsRequest 请求获取当前消费组的元数据信息，当然在这之前还会通过 FindCoordinatorRequest 请求查找消费组对应的 GroupCoordinator。</li>
<li>接着通过 OffsetFetchRequest 请求获取消费位移 ConsumerOffset。</li>
<li>然后通过 KafkaConsumer 的 endOffsets(Collection partitions)方法（对应于 ListOffsetRequest 请求）获取 HW（LSO）的值。</li>
<li>最后通过 HW 与 ConsumerOffset 相减得到分区的 Lag，要获得主题的总体 Lag 只需对旗下的各个分区累加即可。</li>
</ul>
</blockquote>
<h3 id="Kafka的那些设计让它有如此高的性能？"><a href="#Kafka的那些设计让它有如此高的性能？" class="headerlink" title="Kafka的那些设计让它有如此高的性能？"></a>Kafka的那些设计让它有如此高的性能？</h3><blockquote>
<ul>
<li><strong>分区：</strong> 主题topic会有多个分区，kafka将分区均匀地分配到整个集群中，当生产者向对应主题传递消息，消息通过负载均衡机制传递到不同的分区以减轻单个服务器实例的压力。<br>一个Consumer Group中可以有多个consumer，多个consumer可以同时消费不同分区的消息，大大的提高了消费者的并行消费能力</li>
<li><strong>网络传输：</strong> 采用批量发送和拉取和端到端的信息压缩，（kafaka会将这些批量的数据进行压缩，将一批消息打包后进行压缩，发送broker服务器后，最终这些数据还是提供给消费者用，所以数据在服务器上还是保持压缩状态，不会进行解压，而且频繁的压缩和解压也会降低性能，最终还是以压缩的方式传递到消费者的手上）</li>
<li><strong>顺序读写：</strong> kafka将消息追加到日志文件中，利用了磁盘的顺序读写，来提高读写效率    </li>
<li><strong>零拷贝：</strong> 零拷贝将文件内容从磁盘通过DMA引擎复制到内核缓冲区，而且没有把数据复制到socket缓冲区，只是将数据位置和长度信息的描述符复制到了socket缓存区，然后直接将数据传输到网络接口，最后发送。这样大大减小了拷贝的次数，提高了效率。kafka正是调用linux系统给出的sendfile系统调用来使用零拷贝。Java中的系统调用给出的是FileChannel.transferTo接口。</li>
<li><strong>存储机制：</strong> 如果分区规则设置得合理，那么所有的消息可以均匀地分布到不同的分区中，这样就可以实现水平扩展。不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止 Log 过大，Kafka 又引入了日志分段（LogSegment）的概念，将 Log 切分为多个 LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。  <img src="/rookie/2022/08/01/kafka/kafka4/log-construct.png" class="" title="img.png">
Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由 broker 端参数 log.index.interval.bytes 指定，默认值为4096，即 4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小 log.index.interval.bytes 的值，对应地可以增加或缩小索引项的密度。</li>
</ul>
</blockquote>
<h3 id="Kafka有什么优缺点？"><a href="#Kafka有什么优缺点？" class="headerlink" title="Kafka有什么优缺点？"></a>Kafka有什么优缺点？</h3><h3 id="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"><a href="#还用过什么同质类的其它产品，与Kafka相比有什么优缺点？" class="headerlink" title="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"></a>还用过什么同质类的其它产品，与Kafka相比有什么优缺点？</h3><h3 id="为什么选择Kafka"><a href="#为什么选择Kafka" class="headerlink" title="为什么选择Kafka?"></a>为什么选择Kafka?</h3><h3 id="在使用Kafka的过程中遇到过什么困难？怎么解决的？"><a href="#在使用Kafka的过程中遇到过什么困难？怎么解决的？" class="headerlink" title="在使用Kafka的过程中遇到过什么困难？怎么解决的？"></a>在使用Kafka的过程中遇到过什么困难？怎么解决的？</h3><h3 id="怎么样才能确保Kafka极大程度上的可靠性？"><a href="#怎么样才能确保Kafka极大程度上的可靠性？" class="headerlink" title="怎么样才能确保Kafka极大程度上的可靠性？"></a>怎么样才能确保Kafka极大程度上的可靠性？</h3><h3 id="聊一聊你对Kafka生态的理解"><a href="#聊一聊你对Kafka生态的理解" class="headerlink" title="聊一聊你对Kafka生态的理解"></a>聊一聊你对Kafka生态的理解</h3>]]></content>
      <tags>
        <tag>kafka 面试题</tag>
      </tags>
  </entry>
</search>
