<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>kafka常见面试题以及答案整理 | Rookie的博客</title><meta name="author" content="peng gang"><meta name="copyright" content="peng gang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="kafka必会面试题，从基础到高端，再也不怕面试官问kafka了">
<meta property="og:type" content="article">
<meta property="og:title" content="kafka常见面试题以及答案整理">
<meta property="og:url" content="http://ailydia.top/2022/08/01/kafka/kafka4/index.html">
<meta property="og:site_name" content="Rookie的博客">
<meta property="og:description" content="kafka必会面试题，从基础到高端，再也不怕面试官问kafka了">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://ailydia.top/images/myHead.jpg">
<meta property="article:published_time" content="2022-08-01T13:40:57.000Z">
<meta property="article:modified_time" content="2022-08-09T13:14:00.848Z">
<meta property="article:author" content="peng gang">
<meta property="article:tag" content="kafka 面试题">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://ailydia.top/images/myHead.jpg"><link rel="shortcut icon" href="/images/myHead.jpg"><link rel="canonical" href="http://ailydia.top/2022/08/01/kafka/kafka4/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'kafka常见面试题以及答案整理',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-09 21:14:00'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/web_page.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/myHead.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 多媒体</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Rookie的博客"><span class="site-name">Rookie的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 多媒体</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">kafka常见面试题以及答案整理</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-01T13:40:57.000Z" title="发表于 2022-08-01 21:40:57">2022-08-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-09T13:14:00.848Z" title="更新于 2022-08-09 21:14:00">2022-08-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="kafka常见面试题以及答案整理"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="Kafka的用途有哪些？使用场景如何？"><a href="#Kafka的用途有哪些？使用场景如何？" class="headerlink" title="Kafka的用途有哪些？使用场景如何？"></a>Kafka的用途有哪些？使用场景如何？</h3><blockquote>
</blockquote>
<h3 id="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"><a href="#Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么" class="headerlink" title="Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么"></a>Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</h3><blockquote>
<p><strong>ISR</strong>：所有与leader副本保持一定程度同步的副本（包括leader副本在内），（In-Sync Replicas）<br><strong>OSR</strong>：与leader副本同步滞后过多或断开连接的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas），<br>时间阈值由replica.lag.time.max.ms配置，默认30S<br><strong>AR</strong>：所有的副本列表统称AR（Assigned Replicas）<br><strong>ISR伸缩</strong>：leader副本负责维护和跟踪 ISR 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。<br>如果 OSR 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变</p>
</blockquote>
<h3 id="Kafka中的HW、LEO、LSO、LW等分别代表什么？"><a href="#Kafka中的HW、LEO、LSO、LW等分别代表什么？" class="headerlink" title="Kafka中的HW、LEO、LSO、LW等分别代表什么？"></a>Kafka中的HW、LEO、LSO、LW等分别代表什么？</h3><blockquote>
<p><strong>HW</strong>:High Watermark 高水位线，所有副本中最小的offset,即ISR中副本最小的LEO<br><strong>LEO</strong>:Log End Offset，每个副本当前日志文件中下一条待写入消息的offset，即最新的Offset+1，<br><strong>LSO</strong>:Last Stable Offset,与kafka 事务有关。对于未完成的事务而言，LSO的值等于事务中的第一条消息所在的位置（firstUnstableOffset）；对于已经完成的事务而言，它的值等同于HW相同<br><strong>LW</strong>:Low Watermark,AR集合中最小的LogStartOffset值。<br><strong>Log Start Offset</strong>：每个副本当前日志文件中写入消息的起始offset</p>
</blockquote>
<blockquote>
<p><strong>消费者配置参数：isolation.level</strong>,这个参数用来配置消费者事务的隔离级别。可选值“read_uncommitted”和“read_committed”，表示消费者所消费到<br>的位置，如果设置为“read_committed”，那么消费这就会忽略事务未提交的消息，即只能消费到LSO(LastStableOffset)的位置，<br>默认配置为”read_uncommitted”,即可以消费到HW（High Watermak）的位置。<br><strong>注：follower副本的事务隔离级别也为“read_uncommitted”，并且不可修改。</strong></p>
</blockquote>
<h3 id="Kafka中是怎么体现消息顺序性的？"><a href="#Kafka中是怎么体现消息顺序性的？" class="headerlink" title="Kafka中是怎么体现消息顺序性的？"></a>Kafka中是怎么体现消息顺序性的？</h3><blockquote>
<p><strong>一定条件下，消息单分区内有序</strong>  </p>
<ul>
<li>在kafka  1.x版本之前需要配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>  </li>
<li>在kafka  1.x版本后，未开启幂等性的情况下必须配置<strong>max.in.flight.requests.per.connect&#x3D;1</strong>，开启幂等性配置（默认开启）可配置<strong>max.in.flight.requests.per.connect&#x3D;5</strong>，<br> 最大为5，因为kafka服务器端会缓存producer5个request的元数据</li>
</ul>
</blockquote>
<h3 id="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h3><blockquote>
<p>拦截器-&gt;序列化器-&gt;分区器</p>
<ul>
<li><strong>拦截器</strong>：用于Client的定制化逻辑处理，比如说过滤不合规则的数据，补充修改消息内容等等，自定义拦截器可以通过实现ProducerInterceptor（生产者的拦截器）接口  </li>
<li><strong>序列化器</strong>： 序列化数据，防止数据丢失  </li>
<li><strong>分区器</strong>：按照一定规则，将数据划分到不同的分区，若未手动指定分区，则使用默认的分区策略，也可通过实现Partitioner实现自定义分区</li>
</ul>
</blockquote>
<h3 id="Kafka生产者客户端的整体结构是什么样子的？"><a href="#Kafka生产者客户端的整体结构是什么样子的？" class="headerlink" title="Kafka生产者客户端的整体结构是什么样子的？"></a>Kafka生产者客户端的整体结构是什么样子的？</h3><img src="/2022/08/01/kafka/kafka4/producer-design.png" class="" title="img.png">
<h3 id="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"><a href="#Kafka生产者客户端中使用了几个线程来处理？分别是什么？" class="headerlink" title="Kafka生产者客户端中使用了几个线程来处理？分别是什么？"></a>Kafka生产者客户端中使用了几个线程来处理？分别是什么？</h3><blockquote>
<p>俩个，main线程和sender线程,具体作用详见上图</p>
</blockquote>
<h3 id="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"><a href="#Kafka的旧版Scala的消费者客户端的设计有什么缺陷？" class="headerlink" title="Kafka的旧版Scala的消费者客户端的设计有什么缺陷？"></a>Kafka的旧版Scala的消费者客户端的设计有什么缺陷？</h3><blockquote>
<p>老版本的 Consumer Group 把位移保存在 ZooKeeper 中,这种大吞吐量的写操作会极大地拖慢 ZooKeeper 集群的性能</p>
</blockquote>
<h3 id="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"><a href="#“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？" class="headerlink" title="“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？"></a>“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</h3><blockquote>
<p>一般来说如果消费者过多，出现了消费者的个数大于分区个数的情况，就会有消费者分配不到任何分区,但是可以通过继承AbstractPartitionAssignor<br>实现自定义消费策略，从而实现同一消费组内的任意消费者都可以消费订阅主题的所有分区，其实就是组内广播，</p>
</blockquote>
<h3 id="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1"><a href="#消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1" class="headerlink" title="消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?"></a>消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</h3><blockquote>
<p>在旧消费者客户端中，消费位移是存储在 ZooKeeper 中的。而在新消费者客户端中，消费位移存储在 Kafka 内部的主题__consumer_offsets 中。<br>当前消费者需要提交的消费位移是offset+1</p>
</blockquote>
<h3 id="有哪些情形会造成重复消费？"><a href="#有哪些情形会造成重复消费？" class="headerlink" title="有哪些情形会造成重复消费？"></a>有哪些情形会造成重复消费？</h3><blockquote>
<ul>
<li><p><strong>Rebalance</strong>:一个consumer正在消费一个分区的一条消息，还没有消费完，发生了rebalance(加入了一个consumer)，从而导致这条消息没有消费成功，rebalance后，另一个consumer又把这条消息消费一遍。</p>
</li>
<li><p><strong>消费者端手动提交</strong>:如果先消费消息，再更新offset位置，导致消息重复消费。</p>
</li>
<li><p><strong>消费者端自动提交</strong>:设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe() 则有可能部分offset没提交，下次重启会重复消费。</p>
</li>
<li><p><strong>生产者端</strong>:生产者因为业务问题导致的宕机，在重启之后可能数据会重发</p>
</li>
</ul>
</blockquote>
<h3 id="那些情景下会造成消息漏消费？"><a href="#那些情景下会造成消息漏消费？" class="headerlink" title="那些情景下会造成消息漏消费？"></a>那些情景下会造成消息漏消费？</h3><blockquote>
<ul>
<li><strong>自动提交</strong>:设置offset为自动定时提交，当offset被自动定时提交时，数据还在内存中未处理，此时刚好把线程kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。</li>
<li><strong>生产者发送消息</strong>:<br>发送消息设置的是fire-and-forget（发后即忘），它只管往 Kafka 中发送消息而并不关心消息是否正确到达。不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。</li>
<li><strong>消费者端</strong>:<br>先提交位移，但是消息还没消费完就宕机了，造成了消息没有被消费。自动位移提交同理</li>
<li><strong>acks没有设置为all</strong>:<br>如果在broker还没把消息同步到其他broker的时候宕机了，那么消息将会丢失</li>
</ul>
</blockquote>
<h3 id="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"><a href="#KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？" class="headerlink" title="KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？"></a>KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</h3><img src="/2022/08/01/kafka/kafka4/multi-thread-consumer.png" class="" title="img.png">
<h3 id="简述消费者与消费组之间的关系"><a href="#简述消费者与消费组之间的关系" class="headerlink" title="简述消费者与消费组之间的关系"></a>简述消费者与消费组之间的关系</h3><blockquote>
<p>Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。<br>Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费</p>
</blockquote>
<h3 id="当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h3><blockquote>
<p>Kafka 会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区，默认情况下这个目录为&#x2F;tmp&#x2F;kafka-logs&#x2F;。<br>在 ZooKeeper 的&#x2F;brokers&#x2F;topics&#x2F;目录下创建一个同名的实节点，该节点中记录了该主题的分区副本分配方案</p>
</blockquote>
<h3 id="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h3><blockquote>
<p>可以增加，使用 kafka-topics 脚本，结合 –alter 参数来增加某个主题的分区数</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt;新分区数&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。<br>首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病的一个方面。<br>其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。<br>最后，Rebalance 实在是太慢了</p>
</blockquote>
<h3 id="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h3><blockquote>
<p>不支持，因为删除的分区中的消息不好处理。如果直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对的</p>
</blockquote>
<h3 id="创建topic时如何选择合适的分区数？"><a href="#创建topic时如何选择合适的分区数？" class="headerlink" title="创建topic时如何选择合适的分区数？"></a>创建topic时如何选择合适的分区数？</h3><blockquote>
<p>可以使用Kafka 本身提供的用于生产者性能测试的 kafka-producer- perf-test.sh 和用于消费者性能测试的 kafka-consumer-perf-test.sh来进行测试。<br>增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。<br>分区数的多少还会影响系统的可用性。如果分区数非常多，如果集群中的某个 broker 节点宕机，那么就会有大量的分区需要同时进行 leader 角色切换，这个切换的过程会耗费一笔可观的时间，并且在这个时间窗口内这些分区也会变得不可用。<br>分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间。</p>
</blockquote>
<h3 id="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"><a href="#Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？" class="headerlink" title="Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？"></a>Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？</h3><blockquote>
<p><strong>__consumer_offsets</strong>：作用是保存 Kafka 消费者的位移信息<br><strong>__transaction_state</strong>：用来存储事务日志消息</p>
</blockquote>
<h3 id="优先副本是什么？它有什么特殊的作用？"><a href="#优先副本是什么？它有什么特殊的作用？" class="headerlink" title="优先副本是什么？它有什么特殊的作用？"></a>优先副本是什么？它有什么特殊的作用？</h3><blockquote>
<p>所谓的优先副本是指在AR集合列表中的第一个副本。理想情况下，优先副本就是该分区的leader 副本，所以也可以称之为 preferred leader。<br>Kafka 要确保所有主题的优先副本在 Kafka 集群中均匀分布，这样就保证了所有分区的 leader 均衡分布。以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”</p>
</blockquote>
<h3 id="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"><a href="#Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理" class="headerlink" title="Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理"></a>Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</h3><blockquote>
<ul>
<li><strong>生产者的分区分配</strong>:是指为每条消息指定其所要发往的分区。可以编写一个具体的类实现org.apache.kafka.clients.producer.Partitioner接口。</li>
<li><strong>消费者中的分区分配</strong>:是指为消费者指定其可以消费消息的分区。Kafka 提供了消费者客户端参数 partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。</li>
<li><strong>分区副本的分配</strong>:是指为集群制定创建主题时的分区副本分配方案，即在哪个 broker 中创建哪些分区的副本。kafka-topics.sh 脚本中提供了一个 replica-assignment 参数来手动指定分区副本的分配方案</li>
</ul>
</blockquote>
<h3 id="简述Kafka的日志目录结构"><a href="#简述Kafka的日志目录结构" class="headerlink" title="简述Kafka的日志目录结构"></a>简述Kafka的日志目录结构</h3><img src="/2022/08/01/kafka/kafka4/log-construct.png" class="" title="img.png">
<h3 id="Kafka中有那些索引文件？"><a href="#Kafka中有那些索引文件？" class="headerlink" title="Kafka中有那些索引文件？"></a>Kafka中有那些索引文件？</h3><blockquote>
<ul>
<li><strong>偏移量索引文件</strong>:用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置</li>
<li><strong>时间戳索引文件</strong>:则根据指定的时间戳（timestamp）来查找对应的偏移量信息。</li>
</ul>
</blockquote>
<h3 id="如果我指定了一个offset，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个offset，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个offset，Kafka怎么查找到对应的消息？"></a>如果我指定了一个offset，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka是通过seek() 方法来指定消费的，在执行seek() 方法之前要去执行一次poll()方法，等到分配到分区之后会去对应的分区的指定位置开始消费，如果指定的位置发生了越界，那么会根据auto.offset.reset 参数设置的情况进行消费。</p>
</blockquote>
<h3 id="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"><a href="#如果我指定了一个timestamp，Kafka怎么查找到对应的消息？" class="headerlink" title="如果我指定了一个timestamp，Kafka怎么查找到对应的消息？"></a>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</h3><blockquote>
<p>Kafka提供了一个 offsetsForTimes() 方法，通过 timestamp 来查询与此对应的分区位置。offsetsForTimes() 方法的参数 timestampsToSearch 是一个 Map 类型，key 为待查询的分区，而 value 为待查询的时间戳，该方法会返回时间戳大于等于待查询时间的第一条消息对应的位置和时间戳，对应于 OffsetAndTimestamp 中的 offset 和 timestamp 字段</p>
</blockquote>
<h3 id="聊一聊你对Kafka的Log-Retention的理解"><a href="#聊一聊你对Kafka的Log-Retention的理解" class="headerlink" title="聊一聊你对Kafka的Log Retention的理解"></a>聊一聊你对Kafka的Log Retention的理解</h3><blockquote>
<p><strong>日志删除：</strong> 配置服务端参数log.cleanup.policy:delete(默认就是delete)</p>
<ul>
<li><strong>基于时间：</strong> 日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值（retentionMs）来寻找可删除的日志分段文件集合（deletableSegments）retentionMs， 可以通过 broker 端参数 log.retention.hours、log.retention.minutes 和 log.retention.ms 来配置，三个配置优先级依次提升。默认情况下只配置了 log.retention.hours 参数，其值为168，即为7天。<br>  删除日志分段时，首先会从 Log 对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作。然后将日志分段所对应的所有文件添加上“.deleted”的后缀（当然也包括对应的索引文件）。最后交由一个以“delete-file”命名的延迟任务来删除这些以“.deleted”为后缀的文件，这个任务的延迟执行时间可以通过 file.delete.delay.ms 参数来调配，此参数的默认值为60000，即1分钟。</li>
<li><strong>基于大小：</strong> 日志删除任务会检查当前日志的大小是否超过设定的阈值（retentionSize）来寻找可删除的日志分段的文件集合（deletableSegments）。<br>  retentionSize 可以通过 broker 端参数 log.retention.bytes 来配置，默认值为-1，表示无穷大。注意 log.retention.bytes 配置的是 Log 中所有日志文件的总大小，而不是单个日志分段（确切地说应该为 .log 日志文件）的大小。单个日志分段的大小由 broker 端参数 log.segment.bytes 来限制，默认值为1073741824，即 1GB</li>
<li><strong>基于日志偏移量：</strong> 这个无法配置，一般不关注，一般情况下日志文件的起始偏移量logStartOffset（logStartOffset值是整个 Log 对象对外可见消息的最小位移值）等于第一个日志分段的baseOffset，但是这并不是绝对的，logStartOffset的值可以通过DeleteRecordsRequest请求、日志的清理和截断等操作修改。</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">log.retention.hours=168 //7d</span><br><span class="line">log.retention.check.interval.ms=300000 //5min log过期检查时间间隔</span><br><span class="line">log.segment.bytes=1073741824 //1G</span><br><span class="line">log.cleaner.delete.retention.ms=86400000 // 1d 标记为deleted的segment的保留时间</span><br><span class="line">log.cleaner.backoff.ms=15000 //15s 清理线程扫描间隔</span><br></pre></td></tr></table></figure>
<h3 id="聊一聊你对Kafka的Log-Compaction的理解"><a href="#聊一聊你对Kafka的Log-Compaction的理解" class="headerlink" title="聊一聊你对Kafka的Log Compaction的理解"></a>聊一聊你对Kafka的Log Compaction的理解</h3><blockquote>
<p><strong>日志压缩：</strong> 配置服务端参数log.cleanup.policy:compact<br>Log Compaction 对于有相同 key 的不同 value 值，只保留最后一个版本。如果应用只关心 key 对应的最新 value 值，则可以开启 Kafka 的日志清理功能，Kafka 会定期将相同 key 的消息进行合并，只保留最新的 value 值，一般可用于用户信息存储等</p>
</blockquote>
<h3 id="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"><a href="#聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）" class="headerlink" title="聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）"></a>聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）</h3><blockquote>
<p><strong>页缓存：</strong> 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I&#x2F;O 的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问，基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。<br>此外，即使 Kafka 服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。  </p>
<p><strong>零拷贝：</strong> 除了消息顺序追加、页缓存等技术，Kafka 还使用零拷贝（Zero-Copy）技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对 Linux 操作系统而言，零拷贝技术依赖于底层的 sendfile() 方法实现。对应于 Java 语言，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法   </p>
</blockquote>
<blockquote>
<p>下图中左侧为传统方式，右侧为零拷贝，详细可见：<a target="_blank" rel="noopener" href="https://developer.ibm.com/articles/j-zerocopy/">https://developer.ibm.com/articles/j-zerocopy/</a></p>
</blockquote>
<img src="/2022/08/01/kafka/kafka4/zero-copy.png" class="" title="img.png">
<h3 id="聊一聊Kafka的延时操作的原理"><a href="#聊一聊Kafka的延时操作的原理" class="headerlink" title="聊一聊Kafka的延时操作的原理"></a>聊一聊Kafka的延时操作的原理</h3><blockquote>
<p>Kafka 中有多种延时操作，比如延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。<br>延时操作创建之后会被加入延时操作管理器（DelayedOperationPurgatory）来做专门的处理。延时操作有可能会超时，每个延时操作管理器都会配备一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现的。</p>
</blockquote>
<h3 id="聊一聊Kafka控制器的作用"><a href="#聊一聊Kafka控制器的作用" class="headerlink" title="聊一聊Kafka控制器的作用"></a>聊一聊Kafka控制器的作用</h3><blockquote>
<p><strong>controller选举：</strong> kafka集群在创建时，会在Zookeeper中创建临时节点 <KafkaZkChroot>&#x2F;controller,创建成功的那个broker为此次的controller,<br>其他的broker会对该控制器节点创建watch对象，监听该节点的变更，当控制器失效后，其他broker会进行抢注，当选新的controller  </p>
<p><strong>controller作用：</strong>  </p>
<ul>
<li>_主题管理_： 主题的创建、删除、修改分区；kafka-topics 脚本相关后台操作基本上都是由controller帮我们完成的</li>
<li>_分区重新分配_：kafka-reassign-partitions 脚本提供的对已有主题分区进行细粒度的分配功能</li>
<li>_Preferred 领导者选举_：当某个broker节点下线重新上线后，该broker节点上的所有分区副本均为Follower，会使分区Leader分布不均匀，这个可以协调Leader</li>
<li>_broker管理_： 自动检测broker的新增、宕机，依赖于利用Watch 机制检查 ZooKeeper 的 &#x2F;brokers&#x2F;ids 节点下的子节点数量变更，因为每个节点在启动后都会在<br>此节点下创建临时节点；</li>
<li>_存储集群数据_：向其他 Broker 提供数据服务。控制器上保存了最全的集群元数据信息，其他所有 Broker 会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据</li>
</ul>
</blockquote>
<h3 id="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"><a href="#消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）" class="headerlink" title="消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）"></a>消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）</h3><ul>
<li><strong><em>名词解释</em></strong><blockquote>
<p><strong>消费者协调器（ConsumerCoordinator）：</strong> 位于消费者客户端的组件，负责与GroupCoordinator通信<br><strong>消费组协调器（GroupCoordinator:）</strong> 位于kafka服务端，用于管理消费组的组件</p>
</blockquote>
</li>
<li><strong><em>什么时候会发生消费者再均衡？</em></strong><blockquote>
<ol>
<li>有新的消费者加入消费组或者宕机下线（不一定真的宕机，有可能只是长时间未与GroupCoordinator发送心跳，默认45秒就被判定掉线）</li>
<li>消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了 unsubscrible() 方法取消对某些主题的订阅</li>
<li>消费组所对应的 GroupCoorinator 节点发生了变更</li>
<li>消费组内所订阅的任一主题或者主题的分区数量发生变化。</li>
</ol>
</blockquote>
</li>
<li><strong><em>消费者消费过程</em></strong><blockquote>
<ol>
<li>FIND_COORDINATOR:确定消费者组对应的GroupCoordinator所在broker，并创建相互通信的网络连接，若连接不正常，就需要向集群中的负载最小的节点发送 FindCoordinatorRequest 请求来查找对应的 GroupCoordinator。  </li>
<li>JOIN_GROUP:消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。且会选择出一个消费者的Leader，并选出大多消费者支持的分区副本分配策略</li>
<li>SYNC_GROUP：消费者Leader将根据阶段二选出分配策略，实施具体的分配方案，并将方案通过GroupCoordinator同步给各个消费者</li>
<li>HEARTBEAT：消费者通过向GroupCoordinator发送心跳来维护自己的活跃性，默认每3秒一次，45秒超时，且心跳和消费是俩个独立的线程</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="Kafka中的幂等是怎么实现的"><a href="#Kafka中的幂等是怎么实现的" class="headerlink" title="Kafka中的幂等是怎么实现的"></a>Kafka中的幂等是怎么实现的</h3><blockquote>
<p>Kafka为此引入了producerId（简称 PID）和序列号（sequence number）这两个概念,每个生产者实例在初始化的时候会被分配一个PID（用户无感知，可以日志文件里查看），<br>对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将 &lt;PID，分区&gt; 对应的序列号的值加1，为每一对 &lt;PID，分区&gt; 维护一个序列号，<br>当出现乱序时，生产者会抛出 OutOfOrderSequenceException</p>
</blockquote>
<h3 id="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）"><a href="#Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ…-”）" class="headerlink" title="Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）"></a>Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）</h3><blockquote>
<p>kafka事务是以幂等性为前提，生产者配置一个transactionalId而生效的；每个transactionalId和PID相对应<br>每次发送数据给&lt;Topic, Partition&gt;前，需要先向事务协调器发送AddPartitionsToTxnRequest，事务协调器会将该&lt;Transaction, Topic, Partition&gt;存于__transaction_state内，并将其状态置为BEGIN。</p>
<p>在处理完 AddOffsetsToTxnRequest 之后，生产者还会发送 TxnOffsetCommitRequest 请求给 GroupCoordinator，从而将本次事务中包含的消费位移信息 offsets 存储到主题 __consumer_offsets 中</p>
<p>一旦上述数据写入操作完成，应用程序必须调用KafkaProducer的commitTransaction方法或者abortTransaction方法以结束当前事务。无论调用 commitTransaction() 方法还是 abortTransaction() 方法，生产者都会向 TransactionCoordinator 发送 EndTxnRequest 请求。<br>TransactionCoordinator 在收到 EndTxnRequest 请求后会执行如下操作：</p>
<p>将 PREPARE_COMMIT 或 PREPARE_ABORT 消息写入主题 __transaction_state<br>通过 WriteTxnMarkersRequest 请求将 COMMIT 或 ABORT 信息写入用户所使用的普通主题和 __consumer_offsets<br>将 COMPLETE_COMMIT 或 COMPLETE_ABORT 信息写入内部主题 __transaction_state标明该事务结束<br>在消费端有一个参数isolation.level，设置为“read_committed”，表示消费端应用不可以看到尚未提交的事务内的消息。如果生产者开启事务并向某个分区值发送3条消息 msg1、msg2 和 msg3，在执行 commitTransaction() 或 abortTransaction() 方法前，设置为“read_committed”的消费端应用是消费不到这些消息的，不过在 KafkaConsumer 内部会缓存这些消息，直到生产者执行 commitTransaction() 方法之后它才能将这些消息推送给消费端应用。反之，如果生产者执行了 abortTransaction() 方法，那么 KafkaConsumer 会将这些缓存的消息丢弃而不推送给消费端应用。</p>
</blockquote>
<h3 id="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h3><blockquote>
</blockquote>
<h3 id="失效副本是指什么？有那些应对措施？"><a href="#失效副本是指什么？有那些应对措施？" class="headerlink" title="失效副本是指什么？有那些应对措施？"></a>失效副本是指什么？有那些应对措施？</h3><blockquote>
<p>正常情况下，分区的所有副本都处于 ISR 集合中，但是难免会有异常情况发生，从而某些副本被剥离出 ISR 集合中。在 ISR 集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即 under-replicated 分区</p>
<p>一般有这几种情况会导致副本失效：</p>
<ul>
<li>follower 副本进程卡住，在一段时间内根本没有向 leader 副本发起同步请求，比如频繁的 Full GC。</li>
<li>follower 副本进程同步过慢，在一段时间内都无法追赶上 leader 副本，比如 I&#x2F;O 开销过大。</li>
<li>如果通过工具增加了副本因子，那么新增加的副本在赶上 leader 副本之前也都是处于失效状态的。</li>
<li>如果一个 follower 副本由于某些原因（比如宕机）而下线，之后又上线，在追赶上 leader 副本之前也处于失效状态</li>
</ul>
</blockquote>
<h3 id="多副本下，各个副本中的HW和LEO的演变过程"><a href="#多副本下，各个副本中的HW和LEO的演变过程" class="headerlink" title="多副本下，各个副本中的HW和LEO的演变过程"></a>多副本下，各个副本中的HW和LEO的演变过程</h3><h3 id="为什么Kafka不支持读写分离？"><a href="#为什么Kafka不支持读写分离？" class="headerlink" title="为什么Kafka不支持读写分离？"></a>为什么Kafka不支持读写分离？</h3><blockquote>
<p><strong>数据一致性问题:</strong> 数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。<br><strong>延时问题:</strong> 数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。  </p>
</blockquote>
<p>对于Kafka来说，必要性不是很高，因为在Kafka集群中，如果存在多个副本，经过合理的配置，可以让leader副本均匀的分布在各个broker上面，使每个 broker 上的读写负载都是一样的。</p>
<h3 id="Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）"><a href="#Kafka在可靠性方面做了哪些改进？（HW-LeaderEpoch）" class="headerlink" title="Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）"></a>Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</h3><blockquote>
<p><strong>HW</strong>: HW 是 High Watermark 的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个 offset 之前的消息。<br>分区 ISR 集合中的每个副本都会维护自身的 LEO，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息</p>
<p><strong>LeaderEpoch:</strong> 代表 leader 的纪元信息（epoch），初始值为0。每当 leader 变更一次，leader epoch 的值就会加1<br>leader epoch 的值就会加1，相当于为 leader 增设了一个版本号。每个副本中还会增设一个矢量 &lt;LeaderEpoch &#x3D;&gt; StartOffset&gt;，<br>其中 StartOffset 表示当前 LeaderEpoch 下写入的第一条消息的偏移量。</p>
</blockquote>
<p>假设有两个节点A和B，B是leader节点，里面的数据如图：</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch1.png" class="" title="img.png">  
<p>A发生重启，之后A不是先忙着截断日志而是先发送OffsetsForLeaderEpochRequest请求给B，B作为目前的leader在收到请求之后会返回当前的LEO（LogEndOffset，注意图中LE0和LEO的不同），与请求对应的响应为OffsetsForLeaderEpochResponse。如果 A 中的 LeaderEpoch（假设为 LE_A）和 B 中的不相同，那么 B 此时会查找 LeaderEpoch 为 LE_A+1 对应的 StartOffset 并返回给 A</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch2.png" class="" title="img_1.png">  
<p>如上图所示，A 在收到2之后发现和目前的 LEO 相同，也就不需要截断日志了，以此来保护数据的完整性。</p>
<p>再如，之后 B 发生了宕机，A 成为新的 leader，那么对应的 LE&#x3D;0 也变成了 LE&#x3D;1，对应的消息 m2 此时就得到了保留。后续的消息都可以以 LE1 为 LeaderEpoch 陆续追加到 A 中。这个时候A就会有两个LE，第二LE所记录的Offset从2开始。如果B恢复了，那么就会从A中获取到LE+1的Offset为2的值返回给B。</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch3.png" class="" title="img_2.png">  
<p>再来看看LE如何解决数据不一致的问题：<br>当前 A 为 leader，B 为 follower，A 中有2条消息 m1 和 m2，而 B 中有1条消息 m1。假设 A 和 B 同时“挂掉”，然后 B 第一个恢复过来并成为新的 leader。</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch4.png" class="" title="img_3.png">  
<p>之后 B 写入消息 m3，并将 LEO 和 HW 更新至2，如下图所示。注意此时的 LeaderEpoch 已经从 LE0 增至 LE1 了。</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch5.png" class="" title="img_4.png">  
<p>紧接着 A 也恢复过来成为 follower 并向 B 发送 OffsetsForLeaderEpochRequest 请求，此时 A 的 LeaderEpoch 为 LE0。B 根据 LE0 查询到对应的 offset 为1并返回给 A，A 就截断日志并删除了消息 m2，如下图所示。之后 A 发送 FetchRequest 至 B 请求来同步数据，最终A和B中都有两条消息 m1 和 m3，HW 和 LEO都为2，并且 LeaderEpoch 都为 LE1，如此便解决了数据不一致的问题。</p>
<img src="/2022/08/01/kafka/kafka4/leaderEpoch6.png" class="" title="img_5.png">  

<h3 id="Kafka中怎么实现死信队列和重试队列？"><a href="#Kafka中怎么实现死信队列和重试队列？" class="headerlink" title="Kafka中怎么实现死信队列和重试队列？"></a>Kafka中怎么实现死信队列和重试队列？</h3><h3 id="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"><a href="#Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）" class="headerlink" title="Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）"></a>Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）</h3><h3 id="Kafka中怎么做消息审计？"><a href="#Kafka中怎么做消息审计？" class="headerlink" title="Kafka中怎么做消息审计？"></a>Kafka中怎么做消息审计？</h3><blockquote>
<p>消息审计是指在消息生产、存储和消费的整个过程之间对消息个数及延迟的审计，以此来检测是否有数据丢失、是否有数据重复、端到端的延迟又是多少等内容。</p>
<p>目前与消息审计有关的产品也有多个，比如 Chaperone（Uber）、Confluent Control Center、Kafka Monitor（LinkedIn），它们主要通过在消息体（value 字段）或在消息头（headers 字段）中内嵌消息对应的时间戳 timestamp 或全局的唯一标识 ID（或者是两者兼备）来实现消息的审计功能。</p>
<p>内嵌 timestamp 的方式主要是设置一个审计的时间间隔 time_bucket_interval（可以自定义设置几秒或几分钟），根据这个 time_bucket_interval 和消息所属的 timestamp 来计算相应的时间桶（time_bucket）。</p>
<p>内嵌 ID 的方式就更加容易理解了，对于每一条消息都会被分配一个全局唯一标识 ID。如果主题和相应的分区固定，则可以为每个分区设置一个全局的 ID。当有消息发送时，首先获取对应的 ID，然后内嵌到消息中，最后才将它发送到 broker 中。消费者进行消费审计时，可以判断出哪条消息丢失、哪条消息重复。</p>
</blockquote>
<h3 id="Kafka中怎么做消息轨迹？"><a href="#Kafka中怎么做消息轨迹？" class="headerlink" title="Kafka中怎么做消息轨迹？"></a>Kafka中怎么做消息轨迹？</h3><blockquote>
<p>消息轨迹指的是一条消息从生产者发出，经由 broker 存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路信息。生产者、broker、消费者这3个角色在处理消息的过程中都会在链路中增加相应的信息，将这些信息汇聚、处理之后就可以查询任意消息的状态，进而为生产环境中的故障排除提供强有力的数据支持。</p>
<p>对消息轨迹而言，最常见的实现方式是封装客户端，在保证正常生产消费的同时添加相应的轨迹信息埋点逻辑。无论生产，还是消费，在执行之后都会有相应的轨迹信息，我们需要将这些信息保存起来。</p>
<p>我们同样可以将轨迹信息保存到 Kafka 的某个主题中，比如下图中的主题 trace_topic。</p>
</blockquote>
<img src="/2022/08/01/kafka/kafka4/messageTrace.png" class="" title="img.png">
<h3 id="Kafka中有那些配置参数比较有意思？聊一聊你的看法"><a href="#Kafka中有那些配置参数比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些配置参数比较有意思？聊一聊你的看法"></a>Kafka中有那些配置参数比较有意思？聊一聊你的看法</h3><h3 id="Kafka中有那些命名比较有意思？聊一聊你的看法"><a href="#Kafka中有那些命名比较有意思？聊一聊你的看法" class="headerlink" title="Kafka中有那些命名比较有意思？聊一聊你的看法"></a>Kafka中有那些命名比较有意思？聊一聊你的看法</h3><h3 id="Kafka有哪些指标需要着重关注？"><a href="#Kafka有哪些指标需要着重关注？" class="headerlink" title="Kafka有哪些指标需要着重关注？"></a>Kafka有哪些指标需要着重关注？</h3><blockquote>
<p>比较重要的 Broker 端 JMX 指标：</p>
<ul>
<li>BytesIn&#x2F;BytesOut：即 Broker 端每秒入站和出站字节数。你要确保这组值不要接近你的网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。</li>
<li>NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减负。</li>
<li>RequestHandlerAvgIdlePercent：即 I&#x2F;O 线程池线程平均的空闲比例。同样地，如果该值长期小于 30%，你需要调整 I&#x2F;O 线程池的数量，或者减少 Broker 端的负载。</li>
<li>UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失。因此，这是一个非常重要的 JMX 指标。</li>
<li>ISRShrink&#x2F;ISRExpand：即 ISR 收缩和扩容的频次指标。如果你的环境中出现 ISR 中副本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出 ISR 的原因，并采取适当的措施。</li>
<li>ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下，Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。</li>
</ul>
</blockquote>
<h3 id="怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同"><a href="#怎么计算Lag？-注意read-uncommitted和read-committed状态下的不同" class="headerlink" title="怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)"></a>怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)</h3><blockquote>
<p>如果消费者客户端的 isolation.level 参数配置为“read_uncommitted”（默认）,它对应的 Lag 等于HW – ConsumerOffset 的值，其中 ConsumerOffset 表示当前的消费位移。</p>
<p>如果这个参数配置为“read_committed”，那么就要引入 LSO 来进行计算了。LSO 是 LastStableOffset 的缩写,它对应的 Lag 等于 LSO – ConsumerOffset 的值。</p>
<ul>
<li>首先通过 DescribeGroupsRequest 请求获取当前消费组的元数据信息，当然在这之前还会通过 FindCoordinatorRequest 请求查找消费组对应的 GroupCoordinator。</li>
<li>接着通过 OffsetFetchRequest 请求获取消费位移 ConsumerOffset。</li>
<li>然后通过 KafkaConsumer 的 endOffsets(Collection partitions)方法（对应于 ListOffsetRequest 请求）获取 HW（LSO）的值。</li>
<li>最后通过 HW 与 ConsumerOffset 相减得到分区的 Lag，要获得主题的总体 Lag 只需对旗下的各个分区累加即可。</li>
</ul>
</blockquote>
<h3 id="Kafka的那些设计让它有如此高的性能？"><a href="#Kafka的那些设计让它有如此高的性能？" class="headerlink" title="Kafka的那些设计让它有如此高的性能？"></a>Kafka的那些设计让它有如此高的性能？</h3><blockquote>
<ul>
<li><strong>分区：</strong> 主题topic会有多个分区，kafka将分区均匀地分配到整个集群中，当生产者向对应主题传递消息，消息通过负载均衡机制传递到不同的分区以减轻单个服务器实例的压力。<br>一个Consumer Group中可以有多个consumer，多个consumer可以同时消费不同分区的消息，大大的提高了消费者的并行消费能力</li>
<li><strong>网络传输：</strong> 采用批量发送和拉取和端到端的信息压缩，（kafaka会将这些批量的数据进行压缩，将一批消息打包后进行压缩，发送broker服务器后，最终这些数据还是提供给消费者用，所以数据在服务器上还是保持压缩状态，不会进行解压，而且频繁的压缩和解压也会降低性能，最终还是以压缩的方式传递到消费者的手上）</li>
<li><strong>顺序读写：</strong> kafka将消息追加到日志文件中，利用了磁盘的顺序读写，来提高读写效率    </li>
<li><strong>零拷贝：</strong> 零拷贝将文件内容从磁盘通过DMA引擎复制到内核缓冲区，而且没有把数据复制到socket缓冲区，只是将数据位置和长度信息的描述符复制到了socket缓存区，然后直接将数据传输到网络接口，最后发送。这样大大减小了拷贝的次数，提高了效率。kafka正是调用linux系统给出的sendfile系统调用来使用零拷贝。Java中的系统调用给出的是FileChannel.transferTo接口。</li>
<li><strong>存储机制：</strong> 如果分区规则设置得合理，那么所有的消息可以均匀地分布到不同的分区中，这样就可以实现水平扩展。不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止 Log 过大，Kafka 又引入了日志分段（LogSegment）的概念，将 Log 切分为多个 LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。  <img src="/2022/08/01/kafka/kafka4/log-construct.png" class="" title="img.png">
Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由 broker 端参数 log.index.interval.bytes 指定，默认值为4096，即 4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小 log.index.interval.bytes 的值，对应地可以增加或缩小索引项的密度。</li>
</ul>
</blockquote>
<h3 id="Kafka有什么优缺点？"><a href="#Kafka有什么优缺点？" class="headerlink" title="Kafka有什么优缺点？"></a>Kafka有什么优缺点？</h3><h3 id="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"><a href="#还用过什么同质类的其它产品，与Kafka相比有什么优缺点？" class="headerlink" title="还用过什么同质类的其它产品，与Kafka相比有什么优缺点？"></a>还用过什么同质类的其它产品，与Kafka相比有什么优缺点？</h3><h3 id="为什么选择Kafka"><a href="#为什么选择Kafka" class="headerlink" title="为什么选择Kafka?"></a>为什么选择Kafka?</h3><h3 id="在使用Kafka的过程中遇到过什么困难？怎么解决的？"><a href="#在使用Kafka的过程中遇到过什么困难？怎么解决的？" class="headerlink" title="在使用Kafka的过程中遇到过什么困难？怎么解决的？"></a>在使用Kafka的过程中遇到过什么困难？怎么解决的？</h3><h3 id="怎么样才能确保Kafka极大程度上的可靠性？"><a href="#怎么样才能确保Kafka极大程度上的可靠性？" class="headerlink" title="怎么样才能确保Kafka极大程度上的可靠性？"></a>怎么样才能确保Kafka极大程度上的可靠性？</h3><h3 id="聊一聊你对Kafka生态的理解"><a href="#聊一聊你对Kafka生态的理解" class="headerlink" title="聊一聊你对Kafka生态的理解"></a>聊一聊你对Kafka生态的理解</h3></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://ailydia.top">peng gang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://ailydia.top/2022/08/01/kafka/kafka4/">http://ailydia.top/2022/08/01/kafka/kafka4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://ailydia.top" target="_blank">Rookie的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/kafka-%E9%9D%A2%E8%AF%95%E9%A2%98/">kafka 面试题</a></div><div class="post_share"><div class="social-share" data-image="/images/myHead.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/10/13/mysql/mysql-index/" title="mysql索引简介"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">mysql索引简介</div></div></a></div><div class="next-post pull-right"><a href="/2022/07/30/kafka/kafka3/" title="kafka-分区原来是这样子"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">kafka-分区原来是这样子</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/myHead.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">peng gang</div><div class="author-info__description">在通往大牛的路上马不停蹄</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">15</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/AhutInfanta/" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="/1713927716@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E7%94%A8%E9%80%94%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E5%A6%82%E4%BD%95%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">Kafka的用途有哪些？使用场景如何？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84ISR%E3%80%81AR%E5%8F%88%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%EF%BC%9FISR%E7%9A%84%E4%BC%B8%E7%BC%A9%E5%8F%88%E6%8C%87%E4%BB%80%E4%B9%88"><span class="toc-number">2.</span> <span class="toc-text">Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84HW%E3%80%81LEO%E3%80%81LSO%E3%80%81LW%E7%AD%89%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">Kafka中的HW、LEO、LSO、LW等分别代表什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%98%AF%E6%80%8E%E4%B9%88%E4%BD%93%E7%8E%B0%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84%EF%BC%9F"><span class="toc-number">4.</span> <span class="toc-text">Kafka中是怎么体现消息顺序性的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84%E5%88%86%E5%8C%BA%E5%99%A8%E3%80%81%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8%E3%80%81%E6%8B%A6%E6%88%AA%E5%99%A8%E6%98%AF%E5%90%A6%E4%BA%86%E8%A7%A3%EF%BC%9F%E5%AE%83%E4%BB%AC%E4%B9%8B%E9%97%B4%E7%9A%84%E5%A4%84%E7%90%86%E9%A1%BA%E5%BA%8F%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%E6%98%AF%E4%BB%80%E4%B9%88%E6%A0%B7%E5%AD%90%E7%9A%84%EF%BC%9F"><span class="toc-number">6.</span> <span class="toc-text">Kafka生产者客户端的整体结构是什么样子的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%BA%86%E5%87%A0%E4%B8%AA%E7%BA%BF%E7%A8%8B%E6%9D%A5%E5%A4%84%E7%90%86%EF%BC%9F%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">7.</span> <span class="toc-text">Kafka生产者客户端中使用了几个线程来处理？分别是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E6%97%A7%E7%89%88Scala%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9C%89%E4%BB%80%E4%B9%88%E7%BC%BA%E9%99%B7%EF%BC%9F"><span class="toc-number">8.</span> <span class="toc-text">Kafka的旧版Scala的消费者客户端的设计有什么缺陷？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%80%9C%E6%B6%88%E8%B4%B9%E7%BB%84%E4%B8%AD%E7%9A%84%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%AA%E6%95%B0%E5%A6%82%E6%9E%9C%E8%B6%85%E8%BF%87topic%E7%9A%84%E5%88%86%E5%8C%BA%EF%BC%8C%E9%82%A3%E4%B9%88%E5%B0%B1%E4%BC%9A%E6%9C%89%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9%E4%B8%8D%E5%88%B0%E6%95%B0%E6%8D%AE%E2%80%9D%E8%BF%99%E5%8F%A5%E8%AF%9D%E6%98%AF%E5%90%A6%E6%AD%A3%E7%A1%AE%EF%BC%9F%E5%A6%82%E6%9E%9C%E4%B8%8D%E6%AD%A3%E7%A1%AE%EF%BC%8C%E9%82%A3%E4%B9%88%E6%9C%89%E6%B2%A1%E6%9C%89%E4%BB%80%E4%B9%88hack%E7%9A%84%E6%89%8B%E6%AE%B5%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%8F%90%E4%BA%A4%E6%B6%88%E8%B4%B9%E4%BD%8D%E7%A7%BB%E6%97%B6%E6%8F%90%E4%BA%A4%E7%9A%84%E6%98%AF%E5%BD%93%E5%89%8D%E6%B6%88%E8%B4%B9%E5%88%B0%E7%9A%84%E6%9C%80%E6%96%B0%E6%B6%88%E6%81%AF%E7%9A%84offset%E8%BF%98%E6%98%AFoffset-1"><span class="toc-number">10.</span> <span class="toc-text">消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%89%E5%93%AA%E4%BA%9B%E6%83%85%E5%BD%A2%E4%BC%9A%E9%80%A0%E6%88%90%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-number">11.</span> <span class="toc-text">有哪些情形会造成重复消费？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%82%A3%E4%BA%9B%E6%83%85%E6%99%AF%E4%B8%8B%E4%BC%9A%E9%80%A0%E6%88%90%E6%B6%88%E6%81%AF%E6%BC%8F%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-number">12.</span> <span class="toc-text">那些情景下会造成消息漏消费？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KafkaConsumer%E6%98%AF%E9%9D%9E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%EF%BC%8C%E9%82%A3%E4%B9%88%E6%80%8E%E4%B9%88%E6%A0%B7%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-number">13.</span> <span class="toc-text">KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E8%BF%B0%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E7%BB%84%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">14.</span> <span class="toc-text">简述消费者与消费组之间的关系</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E4%BD%A0%E4%BD%BF%E7%94%A8kafka-topics-sh%E5%88%9B%E5%BB%BA%EF%BC%88%E5%88%A0%E9%99%A4%EF%BC%89%E4%BA%86%E4%B8%80%E4%B8%AAtopic%E4%B9%8B%E5%90%8E%EF%BC%8CKafka%E8%83%8C%E5%90%8E%E4%BC%9A%E6%89%A7%E8%A1%8C%E4%BB%80%E4%B9%88%E9%80%BB%E8%BE%91%EF%BC%9F"><span class="toc-number">15.</span> <span class="toc-text">当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#topic%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5%E5%A2%9E%E5%8A%A0%EF%BC%9F%E5%A6%82%E6%9E%9C%E5%8F%AF%E4%BB%A5%E6%80%8E%E4%B9%88%E5%A2%9E%E5%8A%A0%EF%BC%9F%E5%A6%82%E6%9E%9C%E4%B8%8D%E5%8F%AF%E4%BB%A5%EF%BC%8C%E9%82%A3%E5%8F%88%E6%98%AF%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">16.</span> <span class="toc-text">topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#topic%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%B0%91%EF%BC%9F%E5%A6%82%E6%9E%9C%E5%8F%AF%E4%BB%A5%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%EF%BC%9F%E5%A6%82%E6%9E%9C%E4%B8%8D%E5%8F%AF%E4%BB%A5%EF%BC%8C%E9%82%A3%E5%8F%88%E6%98%AF%E4%B8%BA%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">17.</span> <span class="toc-text">topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic%E6%97%B6%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E5%88%86%E5%8C%BA%E6%95%B0%EF%BC%9F"><span class="toc-number">18.</span> <span class="toc-text">创建topic时如何选择合适的分区数？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9B%AE%E5%89%8D%E6%9C%89%E9%82%A3%E4%BA%9B%E5%86%85%E9%83%A8topic%EF%BC%8C%E5%AE%83%E4%BB%AC%E9%83%BD%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E5%BE%81%EF%BC%9F%E5%90%84%E8%87%AA%E7%9A%84%E4%BD%9C%E7%94%A8%E5%8F%88%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">19.</span> <span class="toc-text">Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%85%88%E5%89%AF%E6%9C%AC%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%AE%83%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E6%AE%8A%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">20.</span> <span class="toc-text">优先副本是什么？它有什么特殊的作用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%9C%89%E5%93%AA%E5%87%A0%E5%A4%84%E5%9C%B0%E6%96%B9%E6%9C%89%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E7%9A%84%E6%A6%82%E5%BF%B5%EF%BC%9F%E7%AE%80%E8%BF%B0%E5%A4%A7%E8%87%B4%E7%9A%84%E8%BF%87%E7%A8%8B%E5%8F%8A%E5%8E%9F%E7%90%86"><span class="toc-number">21.</span> <span class="toc-text">Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E8%BF%B0Kafka%E7%9A%84%E6%97%A5%E5%BF%97%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-number">22.</span> <span class="toc-text">简述Kafka的日志目录结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%9C%89%E9%82%A3%E4%BA%9B%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6%EF%BC%9F"><span class="toc-number">23.</span> <span class="toc-text">Kafka中有那些索引文件？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%88%91%E6%8C%87%E5%AE%9A%E4%BA%86%E4%B8%80%E4%B8%AAoffset%EF%BC%8CKafka%E6%80%8E%E4%B9%88%E6%9F%A5%E6%89%BE%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">24.</span> <span class="toc-text">如果我指定了一个offset，Kafka怎么查找到对应的消息？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%88%91%E6%8C%87%E5%AE%9A%E4%BA%86%E4%B8%80%E4%B8%AAtimestamp%EF%BC%8CKafka%E6%80%8E%E4%B9%88%E6%9F%A5%E6%89%BE%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84%E6%B6%88%E6%81%AF%EF%BC%9F"><span class="toc-number">25.</span> <span class="toc-text">如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9Kafka%E7%9A%84Log-Retention%E7%9A%84%E7%90%86%E8%A7%A3"><span class="toc-number">26.</span> <span class="toc-text">聊一聊你对Kafka的Log Retention的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9Kafka%E7%9A%84Log-Compaction%E7%9A%84%E7%90%86%E8%A7%A3"><span class="toc-number">27.</span> <span class="toc-text">聊一聊你对Kafka的Log Compaction的理解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9Kafka%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%88%E9%A1%B5%E7%BC%93%E5%AD%98%E3%80%81%E5%86%85%E6%A0%B8%E5%B1%82%E3%80%81%E5%9D%97%E5%B1%82%E3%80%81%E8%AE%BE%E5%A4%87%E5%B1%82%EF%BC%89"><span class="toc-number">28.</span> <span class="toc-text">聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8AKafka%E7%9A%84%E5%BB%B6%E6%97%B6%E6%93%8D%E4%BD%9C%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">29.</span> <span class="toc-text">聊一聊Kafka的延时操作的原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8AKafka%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">30.</span> <span class="toc-text">聊一聊Kafka控制器的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E5%86%8D%E5%9D%87%E8%A1%A1%E7%9A%84%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%EF%BC%88%E6%8F%90%E7%A4%BA%EF%BC%9A%E6%B6%88%E8%B4%B9%E8%80%85%E5%8D%8F%E8%B0%83%E5%99%A8%E5%92%8C%E6%B6%88%E8%B4%B9%E7%BB%84%E5%8D%8F%E8%B0%83%E5%99%A8%EF%BC%89"><span class="toc-number">31.</span> <span class="toc-text">消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84%E5%B9%82%E7%AD%89%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84"><span class="toc-number">32.</span> <span class="toc-text">Kafka中的幂等是怎么实现的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%88%E8%BF%99%E9%A2%98%E6%88%91%E5%8E%BB%E9%9D%A2%E8%AF%956%E5%AE%B6%E8%A2%AB%E9%97%AE4%E6%AC%A1%EF%BC%8C%E7%85%A7%E7%9D%80%E7%AD%94%E6%A1%88%E5%BF%B5%E4%B9%9F%E8%A6%81%E5%BF%B5%E5%8D%81%E5%87%A0%E5%88%86%E9%92%9F%EF%BC%8C%E9%9D%A2%E8%AF%95%E5%AE%98%E7%AE%80%E7%9B%B4%E5%87%91%E4%B8%8D%E8%A6%81%E8%84%B8%E3%80%82%E5%AE%9E%E5%9C%A8%E8%AE%B0%E4%B8%8D%E4%BD%8F%E7%9A%84%E8%AF%9D%E2%80%A6%E5%8F%AA%E8%A6%81%E7%AE%80%E5%8E%86%E4%B8%8A%E4%B8%8D%E5%86%99%E7%B2%BE%E9%80%9AKafka%E4%B8%80%E8%88%AC%E4%B8%8D%E4%BC%9A%E9%97%AE%E5%88%B0%EF%BC%8C%E6%88%91%E7%AE%80%E5%8E%86%E4%B8%8A%E5%86%99%E7%9A%84%E6%98%AF%E2%80%9C%E7%86%9F%E6%82%89Kafka%EF%BC%8C%E4%BA%86%E8%A7%A3RabbitMQ%E2%80%A6-%E2%80%9D%EF%BC%89"><span class="toc-number">33.</span> <span class="toc-text">Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话…只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ….”）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%9C%89%E9%82%A3%E4%BA%9B%E5%9C%B0%E6%96%B9%E9%9C%80%E8%A6%81%E9%80%89%E4%B8%BE%EF%BC%9F%E8%BF%99%E4%BA%9B%E5%9C%B0%E6%96%B9%E7%9A%84%E9%80%89%E4%B8%BE%E7%AD%96%E7%95%A5%E5%8F%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-number">34.</span> <span class="toc-text">Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%B1%E6%95%88%E5%89%AF%E6%9C%AC%E6%98%AF%E6%8C%87%E4%BB%80%E4%B9%88%EF%BC%9F%E6%9C%89%E9%82%A3%E4%BA%9B%E5%BA%94%E5%AF%B9%E6%8E%AA%E6%96%BD%EF%BC%9F"><span class="toc-number">35.</span> <span class="toc-text">失效副本是指什么？有那些应对措施？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%89%AF%E6%9C%AC%E4%B8%8B%EF%BC%8C%E5%90%84%E4%B8%AA%E5%89%AF%E6%9C%AC%E4%B8%AD%E7%9A%84HW%E5%92%8CLEO%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B"><span class="toc-number">36.</span> <span class="toc-text">多副本下，各个副本中的HW和LEO的演变过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88Kafka%E4%B8%8D%E6%94%AF%E6%8C%81%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%9F"><span class="toc-number">37.</span> <span class="toc-text">为什么Kafka不支持读写分离？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E5%9C%A8%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%96%B9%E9%9D%A2%E5%81%9A%E4%BA%86%E5%93%AA%E4%BA%9B%E6%94%B9%E8%BF%9B%EF%BC%9F%EF%BC%88HW-LeaderEpoch%EF%BC%89"><span class="toc-number">38.</span> <span class="toc-text">Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%E5%92%8C%E9%87%8D%E8%AF%95%E9%98%9F%E5%88%97%EF%BC%9F"><span class="toc-number">39.</span> <span class="toc-text">Kafka中怎么实现死信队列和重试队列？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E7%9A%84%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%88%E8%BF%99%E9%A2%98%E8%A2%AB%E9%97%AE%E7%9A%84%E6%AF%94%E4%BA%8B%E5%8A%A1%E9%82%A3%E9%A2%98%E8%BF%98%E8%A6%81%E5%A4%9A%EF%BC%81%EF%BC%81%EF%BC%81%E5%90%AC%E8%AF%B4%E4%BD%A0%E4%BC%9AKafka%EF%BC%8C%E9%82%A3%E4%BD%A0%E8%AF%B4%E8%AF%B4%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%EF%BC%9F%EF%BC%89"><span class="toc-number">40.</span> <span class="toc-text">Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%80%8E%E4%B9%88%E5%81%9A%E6%B6%88%E6%81%AF%E5%AE%A1%E8%AE%A1%EF%BC%9F"><span class="toc-number">41.</span> <span class="toc-text">Kafka中怎么做消息审计？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%80%8E%E4%B9%88%E5%81%9A%E6%B6%88%E6%81%AF%E8%BD%A8%E8%BF%B9%EF%BC%9F"><span class="toc-number">42.</span> <span class="toc-text">Kafka中怎么做消息轨迹？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%9C%89%E9%82%A3%E4%BA%9B%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E6%AF%94%E8%BE%83%E6%9C%89%E6%84%8F%E6%80%9D%EF%BC%9F%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E7%9A%84%E7%9C%8B%E6%B3%95"><span class="toc-number">43.</span> <span class="toc-text">Kafka中有那些配置参数比较有意思？聊一聊你的看法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E4%B8%AD%E6%9C%89%E9%82%A3%E4%BA%9B%E5%91%BD%E5%90%8D%E6%AF%94%E8%BE%83%E6%9C%89%E6%84%8F%E6%80%9D%EF%BC%9F%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E7%9A%84%E7%9C%8B%E6%B3%95"><span class="toc-number">44.</span> <span class="toc-text">Kafka中有那些命名比较有意思？聊一聊你的看法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%9C%89%E5%93%AA%E4%BA%9B%E6%8C%87%E6%A0%87%E9%9C%80%E8%A6%81%E7%9D%80%E9%87%8D%E5%85%B3%E6%B3%A8%EF%BC%9F"><span class="toc-number">45.</span> <span class="toc-text">Kafka有哪些指标需要着重关注？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%AE%A1%E7%AE%97Lag%EF%BC%9F-%E6%B3%A8%E6%84%8Fread-uncommitted%E5%92%8Cread-committed%E7%8A%B6%E6%80%81%E4%B8%8B%E7%9A%84%E4%B8%8D%E5%90%8C"><span class="toc-number">46.</span> <span class="toc-text">怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E7%9A%84%E9%82%A3%E4%BA%9B%E8%AE%BE%E8%AE%A1%E8%AE%A9%E5%AE%83%E6%9C%89%E5%A6%82%E6%AD%A4%E9%AB%98%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F"><span class="toc-number">47.</span> <span class="toc-text">Kafka的那些设计让它有如此高的性能？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">48.</span> <span class="toc-text">Kafka有什么优缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%98%E7%94%A8%E8%BF%87%E4%BB%80%E4%B9%88%E5%90%8C%E8%B4%A8%E7%B1%BB%E7%9A%84%E5%85%B6%E5%AE%83%E4%BA%A7%E5%93%81%EF%BC%8C%E4%B8%8EKafka%E7%9B%B8%E6%AF%94%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">49.</span> <span class="toc-text">还用过什么同质类的其它产品，与Kafka相比有什么优缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E6%8B%A9Kafka"><span class="toc-number">50.</span> <span class="toc-text">为什么选择Kafka?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%BD%BF%E7%94%A8Kafka%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E9%81%87%E5%88%B0%E8%BF%87%E4%BB%80%E4%B9%88%E5%9B%B0%E9%9A%BE%EF%BC%9F%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E7%9A%84%EF%BC%9F"><span class="toc-number">51.</span> <span class="toc-text">在使用Kafka的过程中遇到过什么困难？怎么解决的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E6%A0%B7%E6%89%8D%E8%83%BD%E7%A1%AE%E4%BF%9DKafka%E6%9E%81%E5%A4%A7%E7%A8%8B%E5%BA%A6%E4%B8%8A%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%EF%BC%9F"><span class="toc-number">52.</span> <span class="toc-text">怎么样才能确保Kafka极大程度上的可靠性？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%8A%E4%B8%80%E8%81%8A%E4%BD%A0%E5%AF%B9Kafka%E7%94%9F%E6%80%81%E7%9A%84%E7%90%86%E8%A7%A3"><span class="toc-number">53.</span> <span class="toc-text">聊一聊你对Kafka生态的理解</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/03/15/redis/redisCluster/" title="redisCluster">redisCluster</a><time datetime="2023-03-15T12:34:22.000Z" title="发表于 2023-03-15 20:34:22">2023-03-15</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2023/02/22/springboot/Spring/" title="Spring-基础">Spring-基础</a><time datetime="2023-02-22T13:30:48.000Z" title="发表于 2023-02-22 21:30:48">2023-02-22</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2023/02/20/redis/redisMianShi/" title="redis-面试题">redis-面试题</a><time datetime="2023-02-20T12:35:47.000Z" title="发表于 2023-02-20 20:35:47">2023-02-20</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2023/02/19/java/collection/" title="Collection与Map">Collection与Map</a><time datetime="2023-02-19T04:46:14.000Z" title="发表于 2023-02-19 12:46:14">2023-02-19</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2023/02/19/redis/redisDataType/" title="redis">redis</a><time datetime="2023-02-19T04:13:27.000Z" title="发表于 2023-02-19 12:13:27">2023-02-19</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By peng gang</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"log":false});</script></body></html>